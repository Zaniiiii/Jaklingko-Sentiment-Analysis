{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgp1M7IhC1T3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17dc49d2-150e-433d-e3d6-1d7d8bc10495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/7.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/7.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/7.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install Sastrawi\n",
        "!pip install Keras-Preprocessing\n",
        "!pip install tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from keras.models import save_model\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras.backend as K\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ],
      "metadata": {
        "id": "2wxgGDmGD-iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = 'https://raw.githubusercontent.com/Zaniiiii/DataGemas/main/Baru/cleaning_result%20v1.csv'\n",
        "df1 = pd.read_csv(df1, sep=\",\")\n",
        "df = df1\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LHMWpdxDDpA5",
        "outputId": "8748e289-9f61-4277-c079-24ad7b059ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           full_text  \\\n",
              "0  padahal nih yah ga usah pada banyak cingcong i...   \n",
              "1  Bisa naik jaklingko dari cipayung ke tamini 0 ...   \n",
              "2  gw banget lagi terus naik jaklingko gratis ke ...   \n",
              "3  Ya mesti dibuat Stasiun baru karna Stasiun ter...   \n",
              "4  Nilai tauladan yg bisa diambil dari nunggu jak...   \n",
              "\n",
              "                                          text_clean  class  \n",
              "0  perlu cingcong orang surabaya bandung medan ni...      0  \n",
              "1  naik jaklingko cipayung tamini rupiah wkwkwk l...      1  \n",
              "2           banget terus naik jaklingko gratis pelni      1  \n",
              "3  mesti buat stasiun baru stasiun dekat ancol ha...      2  \n",
              "4  nilai tauladan ambil nunggu jaklingko gin yaki...      0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-baf6df8a-789a-4f13-b855-16bf55ff55f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>padahal nih yah ga usah pada banyak cingcong i...</td>\n",
              "      <td>perlu cingcong orang surabaya bandung medan ni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bisa naik jaklingko dari cipayung ke tamini 0 ...</td>\n",
              "      <td>naik jaklingko cipayung tamini rupiah wkwkwk l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gw banget lagi terus naik jaklingko gratis ke ...</td>\n",
              "      <td>banget terus naik jaklingko gratis pelni</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ya mesti dibuat Stasiun baru karna Stasiun ter...</td>\n",
              "      <td>mesti buat stasiun baru stasiun dekat ancol ha...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nilai tauladan yg bisa diambil dari nunggu jak...</td>\n",
              "      <td>nilai tauladan ambil nunggu jaklingko gin yaki...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baf6df8a-789a-4f13-b855-16bf55ff55f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-161b7129-ccaf-46c4-bb15-74cec2183786\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-161b7129-ccaf-46c4-bb15-74cec2183786')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-161b7129-ccaf-46c4-bb15-74cec2183786 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-baf6df8a-789a-4f13-b855-16bf55ff55f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-baf6df8a-789a-4f13-b855-16bf55ff55f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df['text_clean']\n",
        "df['tweet']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sXLSPESz-9w",
        "outputId": "2345c307-1830-4f23-ccd6-4359b086004e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       perlu cingcong orang surabaya bandung medan ni...\n",
              "1       naik jaklingko cipayung tamini rupiah wkwkwk l...\n",
              "2                banget terus naik jaklingko gratis pelni\n",
              "3       mesti buat stasiun baru stasiun dekat ancol ha...\n",
              "4       nilai tauladan ambil nunggu jaklingko gin yaki...\n",
              "                              ...                        \n",
              "1195    transjakarta angkot jaklingko sekarang galak b...\n",
              "1196    ombgunan tugu skali tiada kmanfaatanya warga p...\n",
              "1197    transjakarta jarak angkot jaklingko masuk oper...\n",
              "1198    nunggu jaklingko pulang kerja harap perintah m...\n",
              "1199    halo betul nemu tweet cari cara pakai transpor...\n",
              "Name: tweet, Length: 1200, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(df['tweet'].tolist())\n",
        "y = np.array(df['class'].tolist())\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "D2gDQiDQ0Ccb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCjsFpSW31uO",
        "outputId": "6797e5b4-b84a-490f-f9fc-b7cdd9a640ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(960,)\n",
            "(960,)\n",
            "(240,)\n",
            "(240,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "className = {\n",
        "    0: -1,\n",
        "    1: 1,\n",
        "    2: 2\n",
        "}\n",
        "\n",
        "def oneHotEncode(listArray):\n",
        "    s = (len(listArray), len(np.unique(listArray)))\n",
        "    tempData = np.zeros(s)\n",
        "    for i in range(len(listArray)):\n",
        "        if listArray[i] == 1:\n",
        "            tempData[i][1] = 1\n",
        "        elif listArray[i] == -1:\n",
        "            tempData[i][0] = 1\n",
        "        elif listArray[i] == 2:\n",
        "            tempData[i][2] = 1\n",
        "    return tempData\n",
        "\n",
        "y_train = oneHotEncode(y_train)\n",
        "y_test = oneHotEncode(y_test)"
      ],
      "metadata": {
        "id": "yz6nKQFI0py4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 350\n",
        "max_length = 33\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens=max_vocab_length,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length\n",
        ")\n",
        "text_vectorizer.adapt(X)"
      ],
      "metadata": {
        "id": "CHJSJZkF0x1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5]\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0bcWOtX05Gs",
        "outputId": "e42aaf35-60ee-4f2b-b686-7e907074dc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 350\n",
            "Top 5 most common words: ['', '[UNK]', 'jaklingko', 'naik', 'transjakarta']\n",
            "Bottom 5 least common words: ['error', 'dua', 'depan', 'dana', 'cikini']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = layers.Embedding(\n",
        "    input_dim=max_vocab_length,\n",
        "    output_dim=128,\n",
        "    embeddings_initializer=\"uniform\",\n",
        "    input_length=max_length\n",
        ")\n"
      ],
      "metadata": {
        "id": "QEiH3V9E07Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = random.choice(x_train)\n",
        "print(f\"Original text:\\n{random_sentence}\\n\\nEmbedded version:\")\n",
        "\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f5bs_Tc0-ZE",
        "outputId": "63c12583-63a9-4623-f3e9-b7e25e6fa557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "transjakarta kartu flazz mikro trans angkot jaklingko untuk trans jakarta\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 33, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04039698, -0.01490679,  0.0079907 , ..., -0.03696258,\n",
              "         -0.04255539,  0.01015174],\n",
              "        [ 0.04699235,  0.02622983,  0.02846067, ...,  0.00910113,\n",
              "          0.02711561, -0.04153495],\n",
              "        [-0.03557125,  0.01069098,  0.03911935, ..., -0.04436765,\n",
              "          0.02677329, -0.03076104],\n",
              "        ...,\n",
              "        [ 0.02692716,  0.04234222,  0.04707935, ..., -0.03843965,\n",
              "          0.03891351,  0.01781804],\n",
              "        [ 0.02692716,  0.04234222,  0.04707935, ..., -0.03843965,\n",
              "          0.03891351,  0.01781804],\n",
              "        [ 0.02692716,  0.04234222,  0.04707935, ..., -0.03843965,\n",
              "          0.03891351,  0.01781804]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(x_train)\n",
        "X_train = pad_sequences(X_train, maxlen=max_length)"
      ],
      "metadata": {
        "id": "6MdKk-LK1-c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu')(x)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(x)\n",
        "\n",
        "out = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "out = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "\n",
        "out = tf.keras.layers.Dropout(0.5)(out)\n",
        "\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs, name=\"model_LSTM\")\n"
      ],
      "metadata": {
        "id": "RyBb5-tm1_-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "km-G6r3e2Eih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "36i80uu92Git"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    restore_best_weights=True,\n",
        "    patience=3,\n",
        "    min_delta=0.01,\n",
        "    monitor='val_loss'\n",
        ")"
      ],
      "metadata": {
        "id": "EI1v7ftT2JAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    batch_size=60,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "YphcGdNG2LFh",
        "outputId": "f4fa20d7-bd13-43c0-fe4a-f96552899c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-eb76811275f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/preprocessing/text_vectorization.py\", line 573, in _preprocess\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'text_vectorization_3' (type TextVectorization).\n    \n    When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(60, 33) with rank=2\n    \n    Call arguments received by layer 'text_vectorization_3' (type TextVectorization):\n      • inputs=tf.Tensor(shape=(60, 33), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Baca dataset\n",
        "df1 = 'https://raw.githubusercontent.com/Zaniiiii/DataGemas/main/Baru/cleaning_result%20v1.csv'\n",
        "df1 = pd.read_csv(df1, sep=\",\")\n",
        "df = df1\n",
        "\n",
        "# Kolom tweet sebagai fitur, kolom class sebagai target\n",
        "X = df['text_clean'].values\n",
        "y = df['class'].values\n",
        "\n",
        "# Split data menjadi train set dan test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "# Menggunakan LabelEncoder untuk mengubah label menjadi angka\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "max_vocab_length = 350\n",
        "max_length = 33\n",
        "\n",
        "# Inisialisasi TextVectorization\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens=max_vocab_length,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length\n",
        ")\n",
        "\n",
        "# Adaptasi TextVectorization pada data training\n",
        "text_vectorizer.adapt(x_train)\n",
        "\n",
        "# Inisialisasi model Sequential\n",
        "model = Sequential()\n",
        "\n",
        "# Menambahkan layer TextVectorization pada model\n",
        "model.add(text_vectorizer)\n",
        "\n",
        "# Menambahkan layer Embedding\n",
        "model.add(layers.Embedding(input_dim=max_vocab_length + 1, output_dim=128, input_length=max_length))\n",
        "\n",
        "# Menambahkan layer Conv1D\n",
        "model.add(layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "\n",
        "# Menambahkan layer MaxPooling1D\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Menambahkan layer LSTM\n",
        "model.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.35, return_sequences=True))\n",
        "\n",
        "# Menambahkan layer Flatten\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Menambahkan layer Dense\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Menambahkan layer output dengan softmax activation untuk tiga kelas\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Melatih model\n",
        "model.fit(x_train, y_train, epochs=60, batch_size=60, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "# Melakukan prediksi pada data test\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Melakukan inverse transform pada label hasil prediksi untuk mendapatkan label awal\n",
        "y_pred = label_encoder.inverse_transform(y_pred)\n",
        "y_test = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Membuat laporan klasifikasi\n",
        "classification_result = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31Lk3AMVbY0Q",
        "outputId": "76646f17-28f5-4220-f48e-bf1c0c97012c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "16/16 [==============================] - 3s 58ms/step - loss: 0.9079 - accuracy: 0.6740 - val_loss: 0.8230 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.8177 - accuracy: 0.6833 - val_loss: 0.7923 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.7852 - accuracy: 0.6833 - val_loss: 0.7959 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.7203 - accuracy: 0.6885 - val_loss: 0.8278 - val_accuracy: 0.7042\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.6253 - accuracy: 0.7385 - val_loss: 0.8474 - val_accuracy: 0.6958\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.5504 - accuracy: 0.7583 - val_loss: 0.8483 - val_accuracy: 0.6917\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.4989 - accuracy: 0.7833 - val_loss: 0.9283 - val_accuracy: 0.6792\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.4661 - accuracy: 0.8010 - val_loss: 1.0117 - val_accuracy: 0.6333\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.4108 - accuracy: 0.8188 - val_loss: 1.0855 - val_accuracy: 0.6542\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.3742 - accuracy: 0.8385 - val_loss: 1.2486 - val_accuracy: 0.6583\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.3398 - accuracy: 0.8542 - val_loss: 1.1475 - val_accuracy: 0.6292\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.3031 - accuracy: 0.8740 - val_loss: 1.5195 - val_accuracy: 0.6458\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.3237 - accuracy: 0.8594 - val_loss: 1.4400 - val_accuracy: 0.5875\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.2908 - accuracy: 0.8781 - val_loss: 1.4841 - val_accuracy: 0.6375\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.2493 - accuracy: 0.9062 - val_loss: 1.6256 - val_accuracy: 0.6292\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.2274 - accuracy: 0.9125 - val_loss: 1.5420 - val_accuracy: 0.6500\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.2738 - accuracy: 0.8927 - val_loss: 1.6628 - val_accuracy: 0.7000\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.2471 - accuracy: 0.9073 - val_loss: 1.3601 - val_accuracy: 0.6500\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.1971 - accuracy: 0.9292 - val_loss: 1.5060 - val_accuracy: 0.6500\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.1491 - accuracy: 0.9469 - val_loss: 1.8572 - val_accuracy: 0.6292\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.1488 - accuracy: 0.9510 - val_loss: 1.5478 - val_accuracy: 0.6625\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.1248 - accuracy: 0.9573 - val_loss: 1.8879 - val_accuracy: 0.6042\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.1199 - accuracy: 0.9552 - val_loss: 1.7688 - val_accuracy: 0.6458\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0988 - accuracy: 0.9677 - val_loss: 1.9462 - val_accuracy: 0.6250\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0868 - accuracy: 0.9667 - val_loss: 2.0786 - val_accuracy: 0.6583\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0736 - accuracy: 0.9760 - val_loss: 2.3676 - val_accuracy: 0.6333\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0785 - accuracy: 0.9750 - val_loss: 1.9788 - val_accuracy: 0.6500\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 67ms/step - loss: 0.1030 - accuracy: 0.9667 - val_loss: 1.8563 - val_accuracy: 0.5958\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.1108 - accuracy: 0.9635 - val_loss: 1.8333 - val_accuracy: 0.7000\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.0968 - accuracy: 0.9635 - val_loss: 1.9209 - val_accuracy: 0.6833\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0655 - accuracy: 0.9812 - val_loss: 2.0158 - val_accuracy: 0.7000\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0629 - accuracy: 0.9760 - val_loss: 2.0983 - val_accuracy: 0.6667\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0560 - accuracy: 0.9854 - val_loss: 1.9851 - val_accuracy: 0.6792\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0751 - accuracy: 0.9792 - val_loss: 1.9382 - val_accuracy: 0.6708\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0603 - accuracy: 0.9812 - val_loss: 2.0778 - val_accuracy: 0.7000\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0546 - accuracy: 0.9812 - val_loss: 2.2870 - val_accuracy: 0.6667\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0673 - accuracy: 0.9729 - val_loss: 2.1891 - val_accuracy: 0.6458\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 2.2705 - val_accuracy: 0.6417\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0650 - accuracy: 0.9812 - val_loss: 2.0557 - val_accuracy: 0.6667\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 2.2660 - val_accuracy: 0.6625\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0507 - accuracy: 0.9802 - val_loss: 2.1531 - val_accuracy: 0.6833\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0541 - accuracy: 0.9875 - val_loss: 2.6144 - val_accuracy: 0.6833\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0457 - accuracy: 0.9844 - val_loss: 2.3023 - val_accuracy: 0.6750\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: 2.1782 - val_accuracy: 0.6708\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0454 - accuracy: 0.9865 - val_loss: 2.2397 - val_accuracy: 0.6833\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 68ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 2.1477 - val_accuracy: 0.6917\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 2.3302 - val_accuracy: 0.6667\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 66ms/step - loss: 0.0907 - accuracy: 0.9760 - val_loss: 1.9565 - val_accuracy: 0.6708\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0624 - accuracy: 0.9781 - val_loss: 2.1938 - val_accuracy: 0.6875\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0557 - accuracy: 0.9823 - val_loss: 2.2149 - val_accuracy: 0.6583\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0292 - accuracy: 0.9927 - val_loss: 2.4898 - val_accuracy: 0.6917\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 2.7226 - val_accuracy: 0.6375\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0704 - accuracy: 0.9792 - val_loss: 2.0527 - val_accuracy: 0.6750\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0496 - accuracy: 0.9854 - val_loss: 2.0378 - val_accuracy: 0.6875\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0392 - accuracy: 0.9885 - val_loss: 2.1149 - val_accuracy: 0.6750\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0276 - accuracy: 0.9948 - val_loss: 2.4362 - val_accuracy: 0.6917\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 2.5045 - val_accuracy: 0.6833\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 2.5449 - val_accuracy: 0.7042\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0492 - accuracy: 0.9812 - val_loss: 2.3366 - val_accuracy: 0.6917\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 2.1181 - val_accuracy: 0.6958\n",
            "8/8 [==============================] - 0s 5ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.83      0.80       169\n",
            "           1       0.38      0.30      0.33        27\n",
            "           2       0.49      0.43      0.46        44\n",
            "\n",
            "    accuracy                           0.70       240\n",
            "   macro avg       0.55      0.52      0.53       240\n",
            "weighted avg       0.68      0.70      0.69       240\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "qsSJn7ZDByzN",
        "outputId": "1d3fc2d5-5741-42fd-af46-9b8c815e544c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6efadef3c036>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Akurasi pada data uji:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max = 0\n",
        "for i in range(1,20):\n",
        "\n",
        "  # Baca dataset\n",
        "  df1 = 'https://raw.githubusercontent.com/Zaniiiii/DataGemas/main/Baru/cleaning_result%20v1.csv'\n",
        "  df1 = pd.read_csv(df1, sep=\",\")\n",
        "  df = df1\n",
        "\n",
        "  # Kolom tweet sebagai fitur, kolom class sebagai target\n",
        "  X = df['text_clean'].values\n",
        "  y = df['class'].values\n",
        "\n",
        "  # Split data menjadi train set dan test set\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "  # Menggunakan LabelEncoder untuk mengubah label menjadi angka\n",
        "  label_encoder = LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_test = label_encoder.transform(y_test)\n",
        "\n",
        "  max_vocab_length = 350\n",
        "  max_length = 33\n",
        "\n",
        "  # Inisialisasi TextVectorization\n",
        "  text_vectorizer = TextVectorization(\n",
        "      max_tokens=max_vocab_length,\n",
        "      output_mode=\"int\",\n",
        "      output_sequence_length=max_length\n",
        "  )\n",
        "\n",
        "  # Adaptasi TextVectorization pada data training\n",
        "  text_vectorizer.adapt(x_train)\n",
        "\n",
        "  # Inisialisasi model Sequential\n",
        "  model = Sequential()\n",
        "\n",
        "  # Menambahkan layer TextVectorization pada model\n",
        "  model.add(text_vectorizer)\n",
        "\n",
        "  # Menambahkan layer Embedding\n",
        "  model.add(layers.Embedding(input_dim=max_vocab_length + 1, output_dim=128, input_length=max_length))\n",
        "\n",
        "  # Menambahkan layer Conv1D\n",
        "  model.add(layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "\n",
        "  # Menambahkan layer MaxPooling1D\n",
        "  model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "  # Menambahkan layer LSTM\n",
        "  model.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.35, return_sequences=True))\n",
        "\n",
        "  # Menambahkan layer Flatten\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  # Menambahkan layer Dense\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "  # Menambahkan layer output dengan softmax activation untuk tiga kelas\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # Melatih model\n",
        "  model.fit(x_train, y_train, epochs=60, batch_size=60, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "  # Melakukan prediksi pada data test\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "  # Melakukan inverse transform pada label hasil prediksi untuk mendapatkan label awal\n",
        "  y_pred = label_encoder.inverse_transform(y_pred)\n",
        "  y_test = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "  # Membuat laporan klasifikasi\n",
        "  classification_result = classification_report(y_test, y_pred)\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_result)\n",
        "\n",
        "  _, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Akurasi pada data uji:', test_accuracy)\n",
        "\n",
        "  if test_accuracy > max:\n",
        "    max = test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CHmca8sArXy",
        "outputId": "c98dcc96-8d90-40e2-d798-c0c487ab02c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "16/16 [==============================] - 7s 97ms/step - loss: 0.9061 - accuracy: 0.6656 - val_loss: 0.8193 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.8105 - accuracy: 0.6833 - val_loss: 0.7954 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.7705 - accuracy: 0.6833 - val_loss: 0.7844 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.7276 - accuracy: 0.6938 - val_loss: 0.8272 - val_accuracy: 0.7125\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.6575 - accuracy: 0.7490 - val_loss: 0.7957 - val_accuracy: 0.6542\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.5629 - accuracy: 0.7667 - val_loss: 0.7948 - val_accuracy: 0.6792\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.4252 - accuracy: 0.8344 - val_loss: 0.8931 - val_accuracy: 0.6958\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.3590 - accuracy: 0.8667 - val_loss: 0.9391 - val_accuracy: 0.6833\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.2827 - accuracy: 0.8979 - val_loss: 1.0861 - val_accuracy: 0.6792\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.2185 - accuracy: 0.9167 - val_loss: 1.1529 - val_accuracy: 0.6792\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.2151 - accuracy: 0.9208 - val_loss: 1.2622 - val_accuracy: 0.7208\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.1853 - accuracy: 0.9302 - val_loss: 1.1958 - val_accuracy: 0.6417\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 68ms/step - loss: 0.1311 - accuracy: 0.9594 - val_loss: 1.5307 - val_accuracy: 0.6583\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.1256 - accuracy: 0.9521 - val_loss: 1.5324 - val_accuracy: 0.6458\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.1281 - accuracy: 0.9594 - val_loss: 1.3996 - val_accuracy: 0.6417\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.1095 - accuracy: 0.9646 - val_loss: 1.6862 - val_accuracy: 0.6958\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0938 - accuracy: 0.9708 - val_loss: 1.6701 - val_accuracy: 0.6667\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0725 - accuracy: 0.9729 - val_loss: 1.7134 - val_accuracy: 0.6833\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0717 - accuracy: 0.9771 - val_loss: 1.8118 - val_accuracy: 0.6500\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 1.9506 - val_accuracy: 0.6875\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0693 - accuracy: 0.9740 - val_loss: 2.2235 - val_accuracy: 0.6167\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0689 - accuracy: 0.9760 - val_loss: 1.8199 - val_accuracy: 0.6542\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0665 - accuracy: 0.9823 - val_loss: 2.0418 - val_accuracy: 0.6667\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0880 - accuracy: 0.9750 - val_loss: 1.8912 - val_accuracy: 0.6417\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0692 - accuracy: 0.9740 - val_loss: 1.8929 - val_accuracy: 0.6583\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0709 - accuracy: 0.9802 - val_loss: 2.0521 - val_accuracy: 0.6625\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.1016 - accuracy: 0.9604 - val_loss: 1.8734 - val_accuracy: 0.6583\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0966 - accuracy: 0.9667 - val_loss: 1.8761 - val_accuracy: 0.6958\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0585 - accuracy: 0.9750 - val_loss: 1.7723 - val_accuracy: 0.7042\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 1.9056 - val_accuracy: 0.6750\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 2.1251 - val_accuracy: 0.6708\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0379 - accuracy: 0.9854 - val_loss: 2.4038 - val_accuracy: 0.6792\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 2.4621 - val_accuracy: 0.6958\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 2.1952 - val_accuracy: 0.6667\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 68ms/step - loss: 0.0556 - accuracy: 0.9812 - val_loss: 2.2576 - val_accuracy: 0.6083\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0557 - accuracy: 0.9833 - val_loss: 2.1132 - val_accuracy: 0.6250\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 1.9677 - val_accuracy: 0.6250\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: 2.1740 - val_accuracy: 0.6792\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0363 - accuracy: 0.9927 - val_loss: 2.1997 - val_accuracy: 0.6667\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0402 - accuracy: 0.9854 - val_loss: 2.4484 - val_accuracy: 0.6792\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0389 - accuracy: 0.9885 - val_loss: 2.4804 - val_accuracy: 0.6292\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0439 - accuracy: 0.9844 - val_loss: 2.5017 - val_accuracy: 0.6875\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0610 - accuracy: 0.9812 - val_loss: 2.3303 - val_accuracy: 0.6792\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0468 - accuracy: 0.9823 - val_loss: 2.0616 - val_accuracy: 0.6958\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0395 - accuracy: 0.9917 - val_loss: 2.0499 - val_accuracy: 0.6917\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 2.2076 - val_accuracy: 0.6625\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 2.2520 - val_accuracy: 0.6500\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 2.2807 - val_accuracy: 0.6750\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0355 - accuracy: 0.9875 - val_loss: 2.4004 - val_accuracy: 0.6500\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0301 - accuracy: 0.9937 - val_loss: 2.6004 - val_accuracy: 0.7167\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 2.5459 - val_accuracy: 0.6833\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 2.6347 - val_accuracy: 0.6625\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 2.8227 - val_accuracy: 0.6583\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0317 - accuracy: 0.9885 - val_loss: 2.8231 - val_accuracy: 0.6750\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 2.3442 - val_accuracy: 0.6833\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0543 - accuracy: 0.9812 - val_loss: 1.9778 - val_accuracy: 0.6750\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0391 - accuracy: 0.9865 - val_loss: 2.0865 - val_accuracy: 0.6417\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 2.3410 - val_accuracy: 0.6708\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 2.4866 - val_accuracy: 0.6542\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0350 - accuracy: 0.9875 - val_loss: 2.5287 - val_accuracy: 0.7000\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.83      0.80       169\n",
            "           1       0.39      0.33      0.36        27\n",
            "           2       0.53      0.41      0.46        44\n",
            "\n",
            "    accuracy                           0.70       240\n",
            "   macro avg       0.56      0.53      0.54       240\n",
            "weighted avg       0.68      0.70      0.69       240\n",
            "\n",
            "Akurasi pada data uji: 0.699999988079071\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.9908 - accuracy: 0.6438 - val_loss: 0.8030 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.8236 - accuracy: 0.6833 - val_loss: 0.7949 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.7955 - accuracy: 0.6833 - val_loss: 0.7913 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.7491 - accuracy: 0.6833 - val_loss: 0.8556 - val_accuracy: 0.7083\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.6661 - accuracy: 0.7260 - val_loss: 0.8049 - val_accuracy: 0.7208\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.5764 - accuracy: 0.7563 - val_loss: 0.7893 - val_accuracy: 0.7125\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.5050 - accuracy: 0.7937 - val_loss: 1.0135 - val_accuracy: 0.7083\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.4630 - accuracy: 0.7979 - val_loss: 1.0523 - val_accuracy: 0.6708\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.4232 - accuracy: 0.8229 - val_loss: 1.0498 - val_accuracy: 0.6958\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.3577 - accuracy: 0.8396 - val_loss: 1.2528 - val_accuracy: 0.6583\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 0.3401 - accuracy: 0.8500 - val_loss: 1.2138 - val_accuracy: 0.6500\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.3429 - accuracy: 0.8573 - val_loss: 1.6107 - val_accuracy: 0.6750\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.3149 - accuracy: 0.8740 - val_loss: 1.4309 - val_accuracy: 0.6500\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.2603 - accuracy: 0.8979 - val_loss: 1.5762 - val_accuracy: 0.6750\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.2704 - accuracy: 0.8917 - val_loss: 1.4488 - val_accuracy: 0.6458\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.2424 - accuracy: 0.9042 - val_loss: 1.5338 - val_accuracy: 0.6542\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.2075 - accuracy: 0.9219 - val_loss: 1.5075 - val_accuracy: 0.6625\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1650 - accuracy: 0.9344 - val_loss: 1.7207 - val_accuracy: 0.6542\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.1531 - accuracy: 0.9448 - val_loss: 1.7721 - val_accuracy: 0.6833\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1392 - accuracy: 0.9552 - val_loss: 1.8141 - val_accuracy: 0.6625\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1330 - accuracy: 0.9521 - val_loss: 1.6123 - val_accuracy: 0.6583\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1334 - accuracy: 0.9531 - val_loss: 1.9869 - val_accuracy: 0.6500\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1188 - accuracy: 0.9625 - val_loss: 1.8760 - val_accuracy: 0.6792\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1232 - accuracy: 0.9604 - val_loss: 1.8110 - val_accuracy: 0.6792\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0870 - accuracy: 0.9708 - val_loss: 2.3752 - val_accuracy: 0.6917\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1055 - accuracy: 0.9667 - val_loss: 2.0277 - val_accuracy: 0.6375\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1608 - accuracy: 0.9417 - val_loss: 1.6084 - val_accuracy: 0.6542\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1145 - accuracy: 0.9656 - val_loss: 1.9667 - val_accuracy: 0.6708\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0800 - accuracy: 0.9729 - val_loss: 2.0138 - val_accuracy: 0.6292\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 0.0977 - accuracy: 0.9656 - val_loss: 2.3714 - val_accuracy: 0.6750\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.1235 - accuracy: 0.9594 - val_loss: 1.9083 - val_accuracy: 0.6542\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0932 - accuracy: 0.9729 - val_loss: 1.8012 - val_accuracy: 0.6708\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0639 - accuracy: 0.9781 - val_loss: 1.9675 - val_accuracy: 0.6542\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0595 - accuracy: 0.9802 - val_loss: 2.0780 - val_accuracy: 0.6583\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0640 - accuracy: 0.9812 - val_loss: 1.9880 - val_accuracy: 0.6750\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0545 - accuracy: 0.9792 - val_loss: 1.9537 - val_accuracy: 0.6583\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0508 - accuracy: 0.9802 - val_loss: 2.3013 - val_accuracy: 0.7083\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0533 - accuracy: 0.9792 - val_loss: 2.1158 - val_accuracy: 0.6625\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0420 - accuracy: 0.9885 - val_loss: 2.3911 - val_accuracy: 0.6625\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 2.5759 - val_accuracy: 0.6958\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0432 - accuracy: 0.9844 - val_loss: 2.3598 - val_accuracy: 0.6917\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0835 - accuracy: 0.9771 - val_loss: 1.9549 - val_accuracy: 0.7000\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0513 - accuracy: 0.9844 - val_loss: 1.8760 - val_accuracy: 0.6708\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0374 - accuracy: 0.9906 - val_loss: 2.3658 - val_accuracy: 0.7000\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0787 - accuracy: 0.9792 - val_loss: 2.2637 - val_accuracy: 0.6917\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0478 - accuracy: 0.9865 - val_loss: 2.2495 - val_accuracy: 0.6583\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0479 - accuracy: 0.9812 - val_loss: 2.2241 - val_accuracy: 0.6583\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 2.2653 - val_accuracy: 0.6625\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0431 - accuracy: 0.9875 - val_loss: 2.2287 - val_accuracy: 0.6542\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0528 - accuracy: 0.9844 - val_loss: 2.4132 - val_accuracy: 0.6333\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.0571 - accuracy: 0.9812 - val_loss: 2.1470 - val_accuracy: 0.6625\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0748 - accuracy: 0.9812 - val_loss: 1.9051 - val_accuracy: 0.6875\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0364 - accuracy: 0.9896 - val_loss: 2.2962 - val_accuracy: 0.6375\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 2.3290 - val_accuracy: 0.6708\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0542 - accuracy: 0.9802 - val_loss: 2.4483 - val_accuracy: 0.5958\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0451 - accuracy: 0.9865 - val_loss: 2.3970 - val_accuracy: 0.6708\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 2.3434 - val_accuracy: 0.6917\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0446 - accuracy: 0.9917 - val_loss: 2.3362 - val_accuracy: 0.6875\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0356 - accuracy: 0.9865 - val_loss: 2.3729 - val_accuracy: 0.6542\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0446 - accuracy: 0.9865 - val_loss: 2.4137 - val_accuracy: 0.6667\n",
            "8/8 [==============================] - 0s 9ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.80      0.78       169\n",
            "           1       0.22      0.26      0.24        27\n",
            "           2       0.61      0.39      0.47        44\n",
            "\n",
            "    accuracy                           0.67       240\n",
            "   macro avg       0.53      0.48      0.50       240\n",
            "weighted avg       0.67      0.67      0.66       240\n",
            "\n",
            "Akurasi pada data uji: 0.6666666865348816\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 6s 126ms/step - loss: 0.9228 - accuracy: 0.6635 - val_loss: 0.8356 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.8265 - accuracy: 0.6833 - val_loss: 0.7898 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.7847 - accuracy: 0.6833 - val_loss: 0.7884 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.7247 - accuracy: 0.6885 - val_loss: 0.8164 - val_accuracy: 0.6750\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.6426 - accuracy: 0.7344 - val_loss: 0.8168 - val_accuracy: 0.7042\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.5679 - accuracy: 0.7635 - val_loss: 0.8598 - val_accuracy: 0.7083\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.5328 - accuracy: 0.7896 - val_loss: 0.8944 - val_accuracy: 0.6917\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.4773 - accuracy: 0.7917 - val_loss: 1.1945 - val_accuracy: 0.7042\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.4286 - accuracy: 0.8083 - val_loss: 1.0135 - val_accuracy: 0.6917\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.3889 - accuracy: 0.8354 - val_loss: 1.2999 - val_accuracy: 0.6708\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.3370 - accuracy: 0.8573 - val_loss: 1.2882 - val_accuracy: 0.6417\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.3355 - accuracy: 0.8490 - val_loss: 1.4832 - val_accuracy: 0.6583\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.2973 - accuracy: 0.8823 - val_loss: 1.5243 - val_accuracy: 0.6667\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.2737 - accuracy: 0.8885 - val_loss: 1.7608 - val_accuracy: 0.6583\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.3038 - accuracy: 0.8687 - val_loss: 1.4627 - val_accuracy: 0.6583\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.2922 - accuracy: 0.8865 - val_loss: 1.6629 - val_accuracy: 0.6625\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.2382 - accuracy: 0.8927 - val_loss: 1.8621 - val_accuracy: 0.6333\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.2054 - accuracy: 0.9208 - val_loss: 2.0514 - val_accuracy: 0.6167\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.1931 - accuracy: 0.9312 - val_loss: 2.3707 - val_accuracy: 0.6167\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 0.2092 - accuracy: 0.9187 - val_loss: 1.9276 - val_accuracy: 0.6500\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1800 - accuracy: 0.9354 - val_loss: 2.0850 - val_accuracy: 0.6458\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.1664 - accuracy: 0.9344 - val_loss: 2.1349 - val_accuracy: 0.6250\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.1496 - accuracy: 0.9427 - val_loss: 2.2794 - val_accuracy: 0.6333\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.1450 - accuracy: 0.9500 - val_loss: 2.3209 - val_accuracy: 0.6208\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.1174 - accuracy: 0.9604 - val_loss: 2.3033 - val_accuracy: 0.6458\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.1250 - accuracy: 0.9563 - val_loss: 2.6539 - val_accuracy: 0.6292\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0885 - accuracy: 0.9698 - val_loss: 2.7287 - val_accuracy: 0.6583\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0866 - accuracy: 0.9677 - val_loss: 2.7719 - val_accuracy: 0.6500\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1016 - accuracy: 0.9677 - val_loss: 2.6866 - val_accuracy: 0.6083\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1175 - accuracy: 0.9573 - val_loss: 2.0927 - val_accuracy: 0.6625\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.0938 - accuracy: 0.9729 - val_loss: 2.3637 - val_accuracy: 0.6458\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 2.4840 - val_accuracy: 0.6417\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 2.7250 - val_accuracy: 0.6625\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.1315 - accuracy: 0.9604 - val_loss: 2.3122 - val_accuracy: 0.6875\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.1209 - accuracy: 0.9646 - val_loss: 1.9455 - val_accuracy: 0.6667\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0881 - accuracy: 0.9719 - val_loss: 1.9728 - val_accuracy: 0.6417\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0545 - accuracy: 0.9833 - val_loss: 2.3415 - val_accuracy: 0.6375\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0495 - accuracy: 0.9854 - val_loss: 2.6355 - val_accuracy: 0.6458\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0721 - accuracy: 0.9781 - val_loss: 3.2637 - val_accuracy: 0.6375\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0978 - accuracy: 0.9719 - val_loss: 2.2214 - val_accuracy: 0.6875\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.0433 - accuracy: 0.9865 - val_loss: 2.8935 - val_accuracy: 0.6750\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0677 - accuracy: 0.9760 - val_loss: 2.8791 - val_accuracy: 0.6250\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 2.6278 - val_accuracy: 0.6292\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0635 - accuracy: 0.9823 - val_loss: 2.7473 - val_accuracy: 0.6542\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0581 - accuracy: 0.9781 - val_loss: 2.4714 - val_accuracy: 0.6625\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 0.0535 - accuracy: 0.9802 - val_loss: 2.8070 - val_accuracy: 0.6833\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0382 - accuracy: 0.9896 - val_loss: 2.8167 - val_accuracy: 0.6417\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0596 - accuracy: 0.9812 - val_loss: 2.9454 - val_accuracy: 0.6333\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0438 - accuracy: 0.9844 - val_loss: 2.7990 - val_accuracy: 0.6708\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 2.9450 - val_accuracy: 0.6750\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 2.7612 - val_accuracy: 0.6708\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 2.7850 - val_accuracy: 0.6792\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 2.6803 - val_accuracy: 0.6667\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0348 - accuracy: 0.9865 - val_loss: 2.7358 - val_accuracy: 0.6625\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0346 - accuracy: 0.9854 - val_loss: 2.9859 - val_accuracy: 0.6708\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0331 - accuracy: 0.9906 - val_loss: 3.0300 - val_accuracy: 0.6708\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0355 - accuracy: 0.9906 - val_loss: 3.0833 - val_accuracy: 0.6792\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0461 - accuracy: 0.9823 - val_loss: 2.9205 - val_accuracy: 0.6875\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0571 - accuracy: 0.9833 - val_loss: 2.8957 - val_accuracy: 0.6333\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 2.6003 - val_accuracy: 0.6750\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.79      0.79       169\n",
            "           1       0.35      0.30      0.32        27\n",
            "           2       0.44      0.45      0.45        44\n",
            "\n",
            "    accuracy                           0.68       240\n",
            "   macro avg       0.52      0.51      0.52       240\n",
            "weighted avg       0.67      0.68      0.67       240\n",
            "\n",
            "Akurasi pada data uji: 0.675000011920929\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 5s 100ms/step - loss: 0.9311 - accuracy: 0.6490 - val_loss: 0.8108 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.8146 - accuracy: 0.6833 - val_loss: 0.7901 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.7813 - accuracy: 0.6833 - val_loss: 0.7922 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.7242 - accuracy: 0.6938 - val_loss: 0.7924 - val_accuracy: 0.6917\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.6304 - accuracy: 0.7406 - val_loss: 0.8181 - val_accuracy: 0.7292\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.5564 - accuracy: 0.7677 - val_loss: 0.7790 - val_accuracy: 0.7333\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.4388 - accuracy: 0.8177 - val_loss: 0.8982 - val_accuracy: 0.6792\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.3631 - accuracy: 0.8750 - val_loss: 1.1615 - val_accuracy: 0.7417\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.3382 - accuracy: 0.8667 - val_loss: 0.9145 - val_accuracy: 0.6917\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.2647 - accuracy: 0.9021 - val_loss: 1.1575 - val_accuracy: 0.6125\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.2312 - accuracy: 0.9177 - val_loss: 1.3778 - val_accuracy: 0.6667\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1853 - accuracy: 0.9302 - val_loss: 1.5579 - val_accuracy: 0.7333\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.1856 - accuracy: 0.9396 - val_loss: 1.5067 - val_accuracy: 0.6083\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1648 - accuracy: 0.9438 - val_loss: 1.4190 - val_accuracy: 0.6583\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1170 - accuracy: 0.9583 - val_loss: 1.7048 - val_accuracy: 0.6792\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1266 - accuracy: 0.9615 - val_loss: 1.7563 - val_accuracy: 0.7167\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.1095 - accuracy: 0.9635 - val_loss: 1.7117 - val_accuracy: 0.6917\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1139 - accuracy: 0.9625 - val_loss: 1.5945 - val_accuracy: 0.6500\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.1027 - accuracy: 0.9625 - val_loss: 1.7076 - val_accuracy: 0.5917\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.1082 - accuracy: 0.9604 - val_loss: 1.8734 - val_accuracy: 0.7042\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0925 - accuracy: 0.9646 - val_loss: 1.9257 - val_accuracy: 0.7083\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0769 - accuracy: 0.9760 - val_loss: 2.0118 - val_accuracy: 0.6917\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 2.2650 - val_accuracy: 0.6958\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 2.1698 - val_accuracy: 0.6833\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0754 - accuracy: 0.9729 - val_loss: 2.1214 - val_accuracy: 0.6875\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0585 - accuracy: 0.9844 - val_loss: 2.3355 - val_accuracy: 0.6917\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0524 - accuracy: 0.9854 - val_loss: 2.5400 - val_accuracy: 0.6458\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0567 - accuracy: 0.9781 - val_loss: 2.2252 - val_accuracy: 0.6417\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0838 - accuracy: 0.9708 - val_loss: 2.0067 - val_accuracy: 0.6750\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 2.3036 - val_accuracy: 0.6500\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 2.1602 - val_accuracy: 0.6458\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 2.0382 - val_accuracy: 0.6708\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 2s 109ms/step - loss: 0.0496 - accuracy: 0.9802 - val_loss: 2.1193 - val_accuracy: 0.6875\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0464 - accuracy: 0.9865 - val_loss: 2.3419 - val_accuracy: 0.6750\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0681 - accuracy: 0.9760 - val_loss: 2.2176 - val_accuracy: 0.6833\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.0465 - accuracy: 0.9833 - val_loss: 2.2702 - val_accuracy: 0.6917\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0450 - accuracy: 0.9812 - val_loss: 2.4652 - val_accuracy: 0.6333\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0445 - accuracy: 0.9844 - val_loss: 2.2367 - val_accuracy: 0.6500\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 2.1492 - val_accuracy: 0.6917\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 2.4913 - val_accuracy: 0.6750\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 2.6573 - val_accuracy: 0.6708\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0879 - accuracy: 0.9698 - val_loss: 2.0525 - val_accuracy: 0.6750\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0669 - accuracy: 0.9750 - val_loss: 1.7916 - val_accuracy: 0.6708\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0555 - accuracy: 0.9833 - val_loss: 1.9979 - val_accuracy: 0.7125\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0421 - accuracy: 0.9854 - val_loss: 2.3801 - val_accuracy: 0.7167\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0481 - accuracy: 0.9844 - val_loss: 2.7467 - val_accuracy: 0.6708\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0647 - accuracy: 0.9781 - val_loss: 2.1879 - val_accuracy: 0.7000\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0423 - accuracy: 0.9844 - val_loss: 2.1013 - val_accuracy: 0.6542\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 2.2934 - val_accuracy: 0.6458\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0376 - accuracy: 0.9865 - val_loss: 2.1536 - val_accuracy: 0.6792\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0385 - accuracy: 0.9885 - val_loss: 2.2264 - val_accuracy: 0.6583\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0260 - accuracy: 0.9906 - val_loss: 2.3240 - val_accuracy: 0.6750\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 2.4789 - val_accuracy: 0.6875\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0391 - accuracy: 0.9917 - val_loss: 2.5440 - val_accuracy: 0.6958\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0535 - accuracy: 0.9792 - val_loss: 2.3742 - val_accuracy: 0.7125\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0397 - accuracy: 0.9906 - val_loss: 2.2385 - val_accuracy: 0.6750\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 2.4359 - val_accuracy: 0.6708\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 2.6590 - val_accuracy: 0.6958\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 2.8777 - val_accuracy: 0.6583\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 2.2656 - val_accuracy: 0.6708\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.78      0.78       169\n",
            "           1       0.39      0.33      0.36        27\n",
            "           2       0.44      0.48      0.46        44\n",
            "\n",
            "    accuracy                           0.67       240\n",
            "   macro avg       0.53      0.53      0.53       240\n",
            "weighted avg       0.67      0.67      0.67       240\n",
            "\n",
            "Akurasi pada data uji: 0.6708333492279053\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 7s 103ms/step - loss: 0.9276 - accuracy: 0.6521 - val_loss: 0.8058 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.8145 - accuracy: 0.6833 - val_loss: 0.8033 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.7857 - accuracy: 0.6833 - val_loss: 0.7925 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.7196 - accuracy: 0.6885 - val_loss: 0.8425 - val_accuracy: 0.7125\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.6453 - accuracy: 0.7406 - val_loss: 0.8153 - val_accuracy: 0.7292\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.5903 - accuracy: 0.7552 - val_loss: 0.9164 - val_accuracy: 0.7250\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.5233 - accuracy: 0.7865 - val_loss: 0.9028 - val_accuracy: 0.6917\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.4479 - accuracy: 0.7937 - val_loss: 0.9660 - val_accuracy: 0.7083\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.4096 - accuracy: 0.8385 - val_loss: 1.2080 - val_accuracy: 0.6792\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.3734 - accuracy: 0.8427 - val_loss: 1.2803 - val_accuracy: 0.6458\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.3214 - accuracy: 0.8760 - val_loss: 1.2867 - val_accuracy: 0.6208\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.3048 - accuracy: 0.8719 - val_loss: 1.3455 - val_accuracy: 0.6458\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.2825 - accuracy: 0.8917 - val_loss: 1.4991 - val_accuracy: 0.6417\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.2372 - accuracy: 0.9115 - val_loss: 1.5911 - val_accuracy: 0.6708\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.2430 - accuracy: 0.8990 - val_loss: 1.3564 - val_accuracy: 0.6792\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.2008 - accuracy: 0.9281 - val_loss: 1.5823 - val_accuracy: 0.6667\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.1781 - accuracy: 0.9385 - val_loss: 1.8385 - val_accuracy: 0.6542\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 0.1787 - accuracy: 0.9302 - val_loss: 1.5170 - val_accuracy: 0.6792\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.1665 - accuracy: 0.9406 - val_loss: 1.7404 - val_accuracy: 0.6792\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.1509 - accuracy: 0.9417 - val_loss: 1.8472 - val_accuracy: 0.6708\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.1171 - accuracy: 0.9615 - val_loss: 2.1815 - val_accuracy: 0.6375\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.1094 - accuracy: 0.9635 - val_loss: 1.9890 - val_accuracy: 0.6750\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.1003 - accuracy: 0.9677 - val_loss: 2.3117 - val_accuracy: 0.6875\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0977 - accuracy: 0.9688 - val_loss: 1.9806 - val_accuracy: 0.7000\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0843 - accuracy: 0.9719 - val_loss: 2.4085 - val_accuracy: 0.7000\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0832 - accuracy: 0.9729 - val_loss: 2.4046 - val_accuracy: 0.6250\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0892 - accuracy: 0.9646 - val_loss: 2.2675 - val_accuracy: 0.6625\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0940 - accuracy: 0.9698 - val_loss: 2.4731 - val_accuracy: 0.6792\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0818 - accuracy: 0.9750 - val_loss: 1.8098 - val_accuracy: 0.6792\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0916 - accuracy: 0.9677 - val_loss: 2.0484 - val_accuracy: 0.6958\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0881 - accuracy: 0.9688 - val_loss: 2.1443 - val_accuracy: 0.6458\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0677 - accuracy: 0.9750 - val_loss: 2.4737 - val_accuracy: 0.6792\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0639 - accuracy: 0.9760 - val_loss: 2.3129 - val_accuracy: 0.6542\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0697 - accuracy: 0.9750 - val_loss: 2.0792 - val_accuracy: 0.6542\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0570 - accuracy: 0.9875 - val_loss: 2.3498 - val_accuracy: 0.6333\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 2.5570 - val_accuracy: 0.6417\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 2.6113 - val_accuracy: 0.6750\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.0484 - accuracy: 0.9865 - val_loss: 2.3394 - val_accuracy: 0.6375\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 0.0654 - accuracy: 0.9781 - val_loss: 2.3103 - val_accuracy: 0.6750\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0582 - accuracy: 0.9833 - val_loss: 2.1105 - val_accuracy: 0.6542\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 2.2629 - val_accuracy: 0.6417\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0797 - accuracy: 0.9750 - val_loss: 2.4829 - val_accuracy: 0.6375\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0673 - accuracy: 0.9792 - val_loss: 2.3287 - val_accuracy: 0.6708\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0562 - accuracy: 0.9812 - val_loss: 2.5301 - val_accuracy: 0.6917\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0788 - accuracy: 0.9802 - val_loss: 2.5894 - val_accuracy: 0.7292\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0637 - accuracy: 0.9812 - val_loss: 2.2127 - val_accuracy: 0.6708\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.0578 - accuracy: 0.9771 - val_loss: 2.2438 - val_accuracy: 0.6458\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0616 - accuracy: 0.9833 - val_loss: 2.2455 - val_accuracy: 0.6458\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 2.1186 - val_accuracy: 0.6833\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0354 - accuracy: 0.9917 - val_loss: 2.2651 - val_accuracy: 0.6542\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 2.5114 - val_accuracy: 0.6792\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 2.6310 - val_accuracy: 0.6458\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0389 - accuracy: 0.9844 - val_loss: 2.7331 - val_accuracy: 0.7042\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 2.2587 - val_accuracy: 0.6667\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 2.4121 - val_accuracy: 0.6875\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 2.0997 - val_accuracy: 0.6792\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 2.1353 - val_accuracy: 0.6833\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0387 - accuracy: 0.9865 - val_loss: 2.2707 - val_accuracy: 0.7042\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 2.3066 - val_accuracy: 0.6792\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0492 - accuracy: 0.9823 - val_loss: 2.5056 - val_accuracy: 0.7000\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81       169\n",
            "           1       0.33      0.30      0.31        27\n",
            "           2       0.54      0.34      0.42        44\n",
            "\n",
            "    accuracy                           0.70       240\n",
            "   macro avg       0.55      0.50      0.51       240\n",
            "weighted avg       0.68      0.70      0.68       240\n",
            "\n",
            "Akurasi pada data uji: 0.699999988079071\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 6s 172ms/step - loss: 0.9284 - accuracy: 0.6802 - val_loss: 0.8827 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.8439 - accuracy: 0.6833 - val_loss: 0.8089 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.7908 - accuracy: 0.6833 - val_loss: 0.8294 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.7354 - accuracy: 0.6948 - val_loss: 0.8014 - val_accuracy: 0.7083\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.6356 - accuracy: 0.7458 - val_loss: 0.8149 - val_accuracy: 0.6792\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.5423 - accuracy: 0.7740 - val_loss: 0.8877 - val_accuracy: 0.7333\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.5152 - accuracy: 0.7750 - val_loss: 0.8641 - val_accuracy: 0.6917\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.4727 - accuracy: 0.7958 - val_loss: 0.9360 - val_accuracy: 0.6917\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.3999 - accuracy: 0.8302 - val_loss: 1.0039 - val_accuracy: 0.6708\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.3851 - accuracy: 0.8344 - val_loss: 1.3520 - val_accuracy: 0.7125\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.3613 - accuracy: 0.8427 - val_loss: 1.0878 - val_accuracy: 0.6542\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.3275 - accuracy: 0.8646 - val_loss: 1.4169 - val_accuracy: 0.6417\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.2862 - accuracy: 0.8896 - val_loss: 1.4567 - val_accuracy: 0.6667\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.2854 - accuracy: 0.8792 - val_loss: 1.3262 - val_accuracy: 0.6458\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.2401 - accuracy: 0.9042 - val_loss: 1.6045 - val_accuracy: 0.5917\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.2532 - accuracy: 0.8917 - val_loss: 1.7376 - val_accuracy: 0.6542\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.2241 - accuracy: 0.9156 - val_loss: 1.6177 - val_accuracy: 0.6458\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.2016 - accuracy: 0.9250 - val_loss: 1.5190 - val_accuracy: 0.6625\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.1619 - accuracy: 0.9458 - val_loss: 1.7691 - val_accuracy: 0.6708\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.1743 - accuracy: 0.9333 - val_loss: 1.6995 - val_accuracy: 0.6708\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.2110 - accuracy: 0.9302 - val_loss: 1.4263 - val_accuracy: 0.6333\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.1561 - accuracy: 0.9448 - val_loss: 1.7341 - val_accuracy: 0.6583\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.1236 - accuracy: 0.9531 - val_loss: 1.8474 - val_accuracy: 0.6708\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.1257 - accuracy: 0.9604 - val_loss: 1.8464 - val_accuracy: 0.6542\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.1099 - accuracy: 0.9552 - val_loss: 1.8083 - val_accuracy: 0.6542\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.1000 - accuracy: 0.9656 - val_loss: 2.0099 - val_accuracy: 0.6792\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0953 - accuracy: 0.9719 - val_loss: 1.9239 - val_accuracy: 0.6667\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.1089 - accuracy: 0.9646 - val_loss: 1.8736 - val_accuracy: 0.6333\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0837 - accuracy: 0.9708 - val_loss: 1.9698 - val_accuracy: 0.6708\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0522 - accuracy: 0.9865 - val_loss: 2.2670 - val_accuracy: 0.6625\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0578 - accuracy: 0.9781 - val_loss: 2.5571 - val_accuracy: 0.6167\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0712 - accuracy: 0.9792 - val_loss: 2.3170 - val_accuracy: 0.6583\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0872 - accuracy: 0.9677 - val_loss: 2.0843 - val_accuracy: 0.6958\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0819 - accuracy: 0.9740 - val_loss: 1.8724 - val_accuracy: 0.6708\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0824 - accuracy: 0.9729 - val_loss: 1.9961 - val_accuracy: 0.6542\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0642 - accuracy: 0.9792 - val_loss: 2.1903 - val_accuracy: 0.6542\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0556 - accuracy: 0.9875 - val_loss: 2.2122 - val_accuracy: 0.6875\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 2.1801 - val_accuracy: 0.7042\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0461 - accuracy: 0.9865 - val_loss: 2.3971 - val_accuracy: 0.6792\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0456 - accuracy: 0.9875 - val_loss: 2.2923 - val_accuracy: 0.6875\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0480 - accuracy: 0.9885 - val_loss: 2.2467 - val_accuracy: 0.6917\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0645 - accuracy: 0.9781 - val_loss: 2.0513 - val_accuracy: 0.6833\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0554 - accuracy: 0.9844 - val_loss: 2.0998 - val_accuracy: 0.6750\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 2.1895 - val_accuracy: 0.6833\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0578 - accuracy: 0.9792 - val_loss: 2.1589 - val_accuracy: 0.6792\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 2.1999 - val_accuracy: 0.7167\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0503 - accuracy: 0.9833 - val_loss: 2.2275 - val_accuracy: 0.6625\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0370 - accuracy: 0.9917 - val_loss: 2.3215 - val_accuracy: 0.6792\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 2.3780 - val_accuracy: 0.6500\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 2.5172 - val_accuracy: 0.6667\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0361 - accuracy: 0.9906 - val_loss: 2.5773 - val_accuracy: 0.6958\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0369 - accuracy: 0.9854 - val_loss: 2.5264 - val_accuracy: 0.6458\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0414 - accuracy: 0.9906 - val_loss: 2.2874 - val_accuracy: 0.6625\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0411 - accuracy: 0.9896 - val_loss: 2.3780 - val_accuracy: 0.6625\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0492 - accuracy: 0.9833 - val_loss: 2.2753 - val_accuracy: 0.6917\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 2.3551 - val_accuracy: 0.6583\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0446 - accuracy: 0.9875 - val_loss: 2.4491 - val_accuracy: 0.6917\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 2.1788 - val_accuracy: 0.6875\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0356 - accuracy: 0.9927 - val_loss: 2.1344 - val_accuracy: 0.7000\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 2.3091 - val_accuracy: 0.7125\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.81       169\n",
            "           1       0.38      0.37      0.38        27\n",
            "           2       0.67      0.36      0.47        44\n",
            "\n",
            "    accuracy                           0.71       240\n",
            "   macro avg       0.60      0.53      0.55       240\n",
            "weighted avg       0.70      0.71      0.70       240\n",
            "\n",
            "Akurasi pada data uji: 0.7124999761581421\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 7s 110ms/step - loss: 0.9110 - accuracy: 0.6812 - val_loss: 0.8424 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.8196 - accuracy: 0.6833 - val_loss: 0.8103 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.7681 - accuracy: 0.6833 - val_loss: 0.7896 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.6892 - accuracy: 0.7177 - val_loss: 0.8103 - val_accuracy: 0.7000\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.5967 - accuracy: 0.7521 - val_loss: 0.7961 - val_accuracy: 0.6917\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.5086 - accuracy: 0.7875 - val_loss: 0.9531 - val_accuracy: 0.6625\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.4493 - accuracy: 0.8188 - val_loss: 0.9633 - val_accuracy: 0.6458\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.3731 - accuracy: 0.8615 - val_loss: 1.1120 - val_accuracy: 0.7208\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.3122 - accuracy: 0.8802 - val_loss: 1.1499 - val_accuracy: 0.6625\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.2782 - accuracy: 0.8979 - val_loss: 1.2577 - val_accuracy: 0.6500\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.2255 - accuracy: 0.9240 - val_loss: 1.4843 - val_accuracy: 0.7250\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.2093 - accuracy: 0.9187 - val_loss: 1.3556 - val_accuracy: 0.6292\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.1750 - accuracy: 0.9427 - val_loss: 1.4965 - val_accuracy: 0.6875\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1240 - accuracy: 0.9573 - val_loss: 1.6570 - val_accuracy: 0.6958\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1019 - accuracy: 0.9656 - val_loss: 1.7253 - val_accuracy: 0.7083\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1038 - accuracy: 0.9635 - val_loss: 1.6844 - val_accuracy: 0.6542\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1216 - accuracy: 0.9646 - val_loss: 1.8985 - val_accuracy: 0.7083\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1489 - accuracy: 0.9490 - val_loss: 1.4944 - val_accuracy: 0.6375\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 1.9647 - val_accuracy: 0.6458\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0770 - accuracy: 0.9719 - val_loss: 2.1497 - val_accuracy: 0.7083\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1108 - accuracy: 0.9563 - val_loss: 2.0187 - val_accuracy: 0.6833\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0956 - accuracy: 0.9688 - val_loss: 1.7611 - val_accuracy: 0.6750\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0844 - accuracy: 0.9750 - val_loss: 1.8716 - val_accuracy: 0.6625\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0785 - accuracy: 0.9698 - val_loss: 1.8822 - val_accuracy: 0.6750\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0886 - accuracy: 0.9677 - val_loss: 1.7355 - val_accuracy: 0.7167\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0651 - accuracy: 0.9802 - val_loss: 1.9660 - val_accuracy: 0.6750\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0496 - accuracy: 0.9844 - val_loss: 2.1590 - val_accuracy: 0.7042\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0646 - accuracy: 0.9792 - val_loss: 2.1135 - val_accuracy: 0.6542\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0498 - accuracy: 0.9865 - val_loss: 2.0257 - val_accuracy: 0.7000\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0332 - accuracy: 0.9917 - val_loss: 2.3793 - val_accuracy: 0.6958\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 2.4941 - val_accuracy: 0.6958\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0578 - accuracy: 0.9812 - val_loss: 2.1651 - val_accuracy: 0.6708\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0603 - accuracy: 0.9781 - val_loss: 2.3304 - val_accuracy: 0.6542\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0469 - accuracy: 0.9896 - val_loss: 2.6551 - val_accuracy: 0.6792\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0577 - accuracy: 0.9812 - val_loss: 2.3047 - val_accuracy: 0.6542\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0568 - accuracy: 0.9802 - val_loss: 1.9957 - val_accuracy: 0.6500\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0408 - accuracy: 0.9906 - val_loss: 2.1838 - val_accuracy: 0.6667\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 2.3756 - val_accuracy: 0.6708\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 2.5300 - val_accuracy: 0.6792\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0507 - accuracy: 0.9875 - val_loss: 2.3572 - val_accuracy: 0.6542\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 94ms/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 2.3485 - val_accuracy: 0.6625\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 2.1506 - val_accuracy: 0.6583\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0415 - accuracy: 0.9854 - val_loss: 2.4513 - val_accuracy: 0.6458\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0660 - accuracy: 0.9833 - val_loss: 2.0160 - val_accuracy: 0.6542\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0380 - accuracy: 0.9917 - val_loss: 2.1801 - val_accuracy: 0.7000\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 2.5242 - val_accuracy: 0.6875\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0366 - accuracy: 0.9854 - val_loss: 2.7145 - val_accuracy: 0.6542\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0520 - accuracy: 0.9854 - val_loss: 2.6329 - val_accuracy: 0.6958\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0437 - accuracy: 0.9854 - val_loss: 2.3511 - val_accuracy: 0.6833\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 109ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 2.5069 - val_accuracy: 0.6750\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0403 - accuracy: 0.9896 - val_loss: 2.3492 - val_accuracy: 0.6667\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 2.2988 - val_accuracy: 0.6875\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 2.4036 - val_accuracy: 0.6833\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 2.5850 - val_accuracy: 0.6292\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 2.0991 - val_accuracy: 0.6708\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 2.0723 - val_accuracy: 0.6500\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0438 - accuracy: 0.9917 - val_loss: 2.0041 - val_accuracy: 0.6417\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0389 - accuracy: 0.9906 - val_loss: 2.2563 - val_accuracy: 0.6875\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0267 - accuracy: 0.9896 - val_loss: 2.5730 - val_accuracy: 0.6875\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 2.6123 - val_accuracy: 0.6750\n",
            "8/8 [==============================] - 1s 14ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.80      0.79       169\n",
            "           1       0.37      0.26      0.30        27\n",
            "           2       0.43      0.45      0.44        44\n",
            "\n",
            "    accuracy                           0.68       240\n",
            "   macro avg       0.52      0.50      0.51       240\n",
            "weighted avg       0.67      0.68      0.67       240\n",
            "\n",
            "Akurasi pada data uji: 0.675000011920929\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 5s 105ms/step - loss: 0.9301 - accuracy: 0.6469 - val_loss: 0.8065 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.8242 - accuracy: 0.6833 - val_loss: 0.8025 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.7768 - accuracy: 0.6833 - val_loss: 0.7873 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.7075 - accuracy: 0.6854 - val_loss: 0.8142 - val_accuracy: 0.7042\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.6250 - accuracy: 0.7375 - val_loss: 0.8336 - val_accuracy: 0.6750\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.5533 - accuracy: 0.7656 - val_loss: 0.8666 - val_accuracy: 0.6958\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.5093 - accuracy: 0.7760 - val_loss: 0.8489 - val_accuracy: 0.7208\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 2s 92ms/step - loss: 0.4488 - accuracy: 0.8104 - val_loss: 1.2888 - val_accuracy: 0.7125\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.3837 - accuracy: 0.8229 - val_loss: 1.1483 - val_accuracy: 0.6583\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.3665 - accuracy: 0.8458 - val_loss: 1.1661 - val_accuracy: 0.6750\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.3308 - accuracy: 0.8729 - val_loss: 1.4553 - val_accuracy: 0.6625\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.2744 - accuracy: 0.8948 - val_loss: 1.4143 - val_accuracy: 0.6083\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.2438 - accuracy: 0.9125 - val_loss: 1.3610 - val_accuracy: 0.6792\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1806 - accuracy: 0.9344 - val_loss: 1.8285 - val_accuracy: 0.6833\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1772 - accuracy: 0.9312 - val_loss: 1.7117 - val_accuracy: 0.7125\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 0.1669 - accuracy: 0.9458 - val_loss: 1.5694 - val_accuracy: 0.6833\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.1235 - accuracy: 0.9604 - val_loss: 1.7801 - val_accuracy: 0.6708\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1195 - accuracy: 0.9594 - val_loss: 1.6774 - val_accuracy: 0.6875\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0995 - accuracy: 0.9656 - val_loss: 1.8324 - val_accuracy: 0.6750\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0985 - accuracy: 0.9677 - val_loss: 1.9203 - val_accuracy: 0.6833\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.1098 - accuracy: 0.9594 - val_loss: 2.2372 - val_accuracy: 0.7000\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.1625 - accuracy: 0.9531 - val_loss: 1.4578 - val_accuracy: 0.6583\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0952 - accuracy: 0.9750 - val_loss: 1.7930 - val_accuracy: 0.6625\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0661 - accuracy: 0.9792 - val_loss: 2.1822 - val_accuracy: 0.6875\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.0920 - accuracy: 0.9677 - val_loss: 1.9260 - val_accuracy: 0.7000\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0895 - accuracy: 0.9729 - val_loss: 1.6820 - val_accuracy: 0.6792\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0584 - accuracy: 0.9844 - val_loss: 2.0654 - val_accuracy: 0.7042\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0611 - accuracy: 0.9781 - val_loss: 2.5205 - val_accuracy: 0.7042\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0942 - accuracy: 0.9740 - val_loss: 1.8722 - val_accuracy: 0.7125\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0718 - accuracy: 0.9802 - val_loss: 1.9882 - val_accuracy: 0.6792\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0650 - accuracy: 0.9771 - val_loss: 2.0310 - val_accuracy: 0.6792\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0405 - accuracy: 0.9896 - val_loss: 2.2000 - val_accuracy: 0.6875\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 2.2238 - val_accuracy: 0.6458\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0538 - accuracy: 0.9823 - val_loss: 2.2707 - val_accuracy: 0.6958\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0464 - accuracy: 0.9875 - val_loss: 2.3201 - val_accuracy: 0.6625\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0543 - accuracy: 0.9792 - val_loss: 2.1658 - val_accuracy: 0.6792\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0602 - accuracy: 0.9812 - val_loss: 2.3462 - val_accuracy: 0.6750\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0583 - accuracy: 0.9781 - val_loss: 2.3939 - val_accuracy: 0.7000\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0495 - accuracy: 0.9812 - val_loss: 2.2444 - val_accuracy: 0.6917\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0348 - accuracy: 0.9927 - val_loss: 2.4408 - val_accuracy: 0.6458\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0407 - accuracy: 0.9844 - val_loss: 2.7741 - val_accuracy: 0.6625\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0545 - accuracy: 0.9812 - val_loss: 2.1687 - val_accuracy: 0.6208\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0748 - accuracy: 0.9708 - val_loss: 1.8419 - val_accuracy: 0.6583\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0672 - accuracy: 0.9812 - val_loss: 2.0813 - val_accuracy: 0.6625\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0720 - accuracy: 0.9760 - val_loss: 1.9016 - val_accuracy: 0.6708\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0547 - accuracy: 0.9812 - val_loss: 2.1682 - val_accuracy: 0.7000\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 2.1651 - val_accuracy: 0.6708\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 2.3652 - val_accuracy: 0.6583\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 2.2808 - val_accuracy: 0.7000\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 2.1425 - val_accuracy: 0.7083\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0375 - accuracy: 0.9896 - val_loss: 2.1453 - val_accuracy: 0.6875\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 2.2773 - val_accuracy: 0.6542\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0487 - accuracy: 0.9823 - val_loss: 2.4655 - val_accuracy: 0.7208\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0385 - accuracy: 0.9865 - val_loss: 2.3527 - val_accuracy: 0.7000\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.0325 - accuracy: 0.9875 - val_loss: 2.4597 - val_accuracy: 0.6292\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 2.4890 - val_accuracy: 0.6750\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 2.6001 - val_accuracy: 0.6917\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 2.6374 - val_accuracy: 0.7083\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0382 - accuracy: 0.9854 - val_loss: 2.5676 - val_accuracy: 0.6917\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0289 - accuracy: 0.9927 - val_loss: 2.4242 - val_accuracy: 0.6667\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.79      0.78       169\n",
            "           1       0.31      0.33      0.32        27\n",
            "           2       0.49      0.41      0.44        44\n",
            "\n",
            "    accuracy                           0.67       240\n",
            "   macro avg       0.52      0.51      0.51       240\n",
            "weighted avg       0.66      0.67      0.66       240\n",
            "\n",
            "Akurasi pada data uji: 0.6666666865348816\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 6s 107ms/step - loss: 0.9391 - accuracy: 0.6760 - val_loss: 0.8635 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.8300 - accuracy: 0.6833 - val_loss: 0.7923 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.7871 - accuracy: 0.6833 - val_loss: 0.7880 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.7397 - accuracy: 0.6833 - val_loss: 0.8038 - val_accuracy: 0.7042\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.6980 - accuracy: 0.6844 - val_loss: 0.8195 - val_accuracy: 0.7042\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.6448 - accuracy: 0.7198 - val_loss: 0.8387 - val_accuracy: 0.6292\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.5720 - accuracy: 0.7615 - val_loss: 0.9672 - val_accuracy: 0.6917\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.5102 - accuracy: 0.7854 - val_loss: 1.0047 - val_accuracy: 0.6333\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.4873 - accuracy: 0.8000 - val_loss: 0.9868 - val_accuracy: 0.6542\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 109ms/step - loss: 0.4093 - accuracy: 0.8188 - val_loss: 1.1377 - val_accuracy: 0.6583\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.3545 - accuracy: 0.8406 - val_loss: 1.3199 - val_accuracy: 0.6500\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.3138 - accuracy: 0.8750 - val_loss: 1.4805 - val_accuracy: 0.5708\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.2703 - accuracy: 0.8917 - val_loss: 1.5872 - val_accuracy: 0.5750\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2964 - accuracy: 0.8771 - val_loss: 1.4888 - val_accuracy: 0.6625\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.2538 - accuracy: 0.9010 - val_loss: 1.6263 - val_accuracy: 0.6500\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.1919 - accuracy: 0.9365 - val_loss: 1.9546 - val_accuracy: 0.6625\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.1597 - accuracy: 0.9469 - val_loss: 1.9898 - val_accuracy: 0.6292\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1271 - accuracy: 0.9573 - val_loss: 2.2451 - val_accuracy: 0.5792\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.1362 - accuracy: 0.9500 - val_loss: 2.0032 - val_accuracy: 0.6208\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 1.8679 - val_accuracy: 0.6542\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.1028 - accuracy: 0.9646 - val_loss: 2.2057 - val_accuracy: 0.6167\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0912 - accuracy: 0.9646 - val_loss: 2.2931 - val_accuracy: 0.6500\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0965 - accuracy: 0.9635 - val_loss: 2.4134 - val_accuracy: 0.6208\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0999 - accuracy: 0.9688 - val_loss: 2.0537 - val_accuracy: 0.6458\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0961 - accuracy: 0.9646 - val_loss: 2.1343 - val_accuracy: 0.6167\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1051 - accuracy: 0.9688 - val_loss: 2.1147 - val_accuracy: 0.6708\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0720 - accuracy: 0.9771 - val_loss: 2.2706 - val_accuracy: 0.6500\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0769 - accuracy: 0.9698 - val_loss: 2.2626 - val_accuracy: 0.6292\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0708 - accuracy: 0.9740 - val_loss: 2.3515 - val_accuracy: 0.6500\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0722 - accuracy: 0.9740 - val_loss: 2.1273 - val_accuracy: 0.6917\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0631 - accuracy: 0.9771 - val_loss: 2.3885 - val_accuracy: 0.6333\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0717 - accuracy: 0.9771 - val_loss: 2.5254 - val_accuracy: 0.6500\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0895 - accuracy: 0.9708 - val_loss: 2.3133 - val_accuracy: 0.6625\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0693 - accuracy: 0.9781 - val_loss: 2.1712 - val_accuracy: 0.6375\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0726 - accuracy: 0.9812 - val_loss: 2.4621 - val_accuracy: 0.6667\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0963 - accuracy: 0.9677 - val_loss: 2.1343 - val_accuracy: 0.6375\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0684 - accuracy: 0.9750 - val_loss: 2.0632 - val_accuracy: 0.6625\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0586 - accuracy: 0.9823 - val_loss: 2.3673 - val_accuracy: 0.6625\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 2.5852 - val_accuracy: 0.6458\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0511 - accuracy: 0.9812 - val_loss: 2.6179 - val_accuracy: 0.6708\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0536 - accuracy: 0.9781 - val_loss: 2.3776 - val_accuracy: 0.6292\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0568 - accuracy: 0.9844 - val_loss: 2.4339 - val_accuracy: 0.6500\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0410 - accuracy: 0.9896 - val_loss: 2.3867 - val_accuracy: 0.6708\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 0.0447 - accuracy: 0.9885 - val_loss: 2.6304 - val_accuracy: 0.6417\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0290 - accuracy: 0.9927 - val_loss: 2.8000 - val_accuracy: 0.6333\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0561 - accuracy: 0.9792 - val_loss: 2.8667 - val_accuracy: 0.6417\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 2.8601 - val_accuracy: 0.6417\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 3.2132 - val_accuracy: 0.6333\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0370 - accuracy: 0.9865 - val_loss: 3.0601 - val_accuracy: 0.6583\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0636 - accuracy: 0.9844 - val_loss: 2.8687 - val_accuracy: 0.6500\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0704 - accuracy: 0.9750 - val_loss: 2.6866 - val_accuracy: 0.5792\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0724 - accuracy: 0.9792 - val_loss: 2.6515 - val_accuracy: 0.6083\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0533 - accuracy: 0.9802 - val_loss: 2.6369 - val_accuracy: 0.6458\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 2.8905 - val_accuracy: 0.6542\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0524 - accuracy: 0.9885 - val_loss: 2.7878 - val_accuracy: 0.6500\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0486 - accuracy: 0.9833 - val_loss: 2.4221 - val_accuracy: 0.6542\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 2.6405 - val_accuracy: 0.6333\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.0388 - accuracy: 0.9906 - val_loss: 2.7155 - val_accuracy: 0.6375\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 2.5748 - val_accuracy: 0.6458\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.0319 - accuracy: 0.9917 - val_loss: 2.4805 - val_accuracy: 0.6375\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       169\n",
            "           1       0.26      0.30      0.28        27\n",
            "           2       0.38      0.30      0.33        44\n",
            "\n",
            "    accuracy                           0.64       240\n",
            "   macro avg       0.46      0.46      0.46       240\n",
            "weighted avg       0.63      0.64      0.63       240\n",
            "\n",
            "Akurasi pada data uji: 0.637499988079071\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 6s 108ms/step - loss: 0.9080 - accuracy: 0.6802 - val_loss: 0.8200 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.8145 - accuracy: 0.6833 - val_loss: 0.7919 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.7559 - accuracy: 0.6833 - val_loss: 0.7904 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.6838 - accuracy: 0.6938 - val_loss: 0.8266 - val_accuracy: 0.7208\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.6086 - accuracy: 0.7469 - val_loss: 0.8360 - val_accuracy: 0.6625\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.5181 - accuracy: 0.7750 - val_loss: 0.9417 - val_accuracy: 0.7000\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4695 - accuracy: 0.8000 - val_loss: 0.9373 - val_accuracy: 0.7042\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4490 - accuracy: 0.8073 - val_loss: 0.9167 - val_accuracy: 0.7208\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.4089 - accuracy: 0.8354 - val_loss: 1.2374 - val_accuracy: 0.6833\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.3602 - accuracy: 0.8458 - val_loss: 1.4008 - val_accuracy: 0.6875\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.3644 - accuracy: 0.8323 - val_loss: 1.1584 - val_accuracy: 0.6875\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 0.2968 - accuracy: 0.8781 - val_loss: 1.3860 - val_accuracy: 0.6667\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.2916 - accuracy: 0.8740 - val_loss: 1.4928 - val_accuracy: 0.6833\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2709 - accuracy: 0.8896 - val_loss: 1.4430 - val_accuracy: 0.6625\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.2321 - accuracy: 0.9167 - val_loss: 1.6685 - val_accuracy: 0.6750\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.2235 - accuracy: 0.9146 - val_loss: 1.5315 - val_accuracy: 0.6458\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.2268 - accuracy: 0.9125 - val_loss: 1.5068 - val_accuracy: 0.6583\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1701 - accuracy: 0.9417 - val_loss: 1.6141 - val_accuracy: 0.6958\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1379 - accuracy: 0.9500 - val_loss: 1.7552 - val_accuracy: 0.6708\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1388 - accuracy: 0.9500 - val_loss: 1.6997 - val_accuracy: 0.6833\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.1309 - accuracy: 0.9500 - val_loss: 1.6353 - val_accuracy: 0.6875\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.1162 - accuracy: 0.9521 - val_loss: 1.8506 - val_accuracy: 0.6333\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.1472 - accuracy: 0.9448 - val_loss: 1.7432 - val_accuracy: 0.6500\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1144 - accuracy: 0.9646 - val_loss: 1.6236 - val_accuracy: 0.6917\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0837 - accuracy: 0.9708 - val_loss: 1.8191 - val_accuracy: 0.6875\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0713 - accuracy: 0.9771 - val_loss: 1.9064 - val_accuracy: 0.7167\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0638 - accuracy: 0.9771 - val_loss: 2.2211 - val_accuracy: 0.6333\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0692 - accuracy: 0.9760 - val_loss: 2.1033 - val_accuracy: 0.6958\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.1063 - accuracy: 0.9729 - val_loss: 1.8017 - val_accuracy: 0.6875\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0841 - accuracy: 0.9719 - val_loss: 1.6891 - val_accuracy: 0.7167\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.0684 - accuracy: 0.9823 - val_loss: 2.0014 - val_accuracy: 0.7292\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0907 - accuracy: 0.9698 - val_loss: 1.8354 - val_accuracy: 0.6833\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.1029 - accuracy: 0.9677 - val_loss: 1.6826 - val_accuracy: 0.7125\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 2.1848 - val_accuracy: 0.6667\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 2.3090 - val_accuracy: 0.7333\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 2.0746 - val_accuracy: 0.6875\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0379 - accuracy: 0.9906 - val_loss: 2.2976 - val_accuracy: 0.7000\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 2.3847 - val_accuracy: 0.7125\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0391 - accuracy: 0.9844 - val_loss: 2.2824 - val_accuracy: 0.6792\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 2.1736 - val_accuracy: 0.7292\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0308 - accuracy: 0.9917 - val_loss: 2.3900 - val_accuracy: 0.7125\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 2.4845 - val_accuracy: 0.7208\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0590 - accuracy: 0.9812 - val_loss: 2.4182 - val_accuracy: 0.7375\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0470 - accuracy: 0.9802 - val_loss: 2.1596 - val_accuracy: 0.6875\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1009 - accuracy: 0.9698 - val_loss: 1.8539 - val_accuracy: 0.7333\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0811 - accuracy: 0.9708 - val_loss: 1.8023 - val_accuracy: 0.6500\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0412 - accuracy: 0.9917 - val_loss: 1.9567 - val_accuracy: 0.6792\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 2.1567 - val_accuracy: 0.7000\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0422 - accuracy: 0.9875 - val_loss: 2.1237 - val_accuracy: 0.6917\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 2.2061 - val_accuracy: 0.6917\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 2.2231 - val_accuracy: 0.7208\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 2.4596 - val_accuracy: 0.7333\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0312 - accuracy: 0.9885 - val_loss: 2.5191 - val_accuracy: 0.7208\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 2.3522 - val_accuracy: 0.7167\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 2.2793 - val_accuracy: 0.7167\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0629 - accuracy: 0.9854 - val_loss: 1.7761 - val_accuracy: 0.7000\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0268 - accuracy: 0.9948 - val_loss: 1.9853 - val_accuracy: 0.7083\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.0334 - accuracy: 0.9937 - val_loss: 2.1233 - val_accuracy: 0.7083\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0313 - accuracy: 0.9917 - val_loss: 2.0963 - val_accuracy: 0.7042\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 2.3099 - val_accuracy: 0.7208\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.82       169\n",
            "           1       0.58      0.26      0.36        27\n",
            "           2       0.48      0.48      0.48        44\n",
            "\n",
            "    accuracy                           0.72       240\n",
            "   macro avg       0.62      0.53      0.55       240\n",
            "weighted avg       0.71      0.72      0.71       240\n",
            "\n",
            "Akurasi pada data uji: 0.7208333611488342\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 7s 135ms/step - loss: 0.9341 - accuracy: 0.6448 - val_loss: 0.8276 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.8195 - accuracy: 0.6833 - val_loss: 0.7971 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.7811 - accuracy: 0.6833 - val_loss: 0.7920 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.7284 - accuracy: 0.6906 - val_loss: 0.8233 - val_accuracy: 0.7000\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.6319 - accuracy: 0.7344 - val_loss: 0.8480 - val_accuracy: 0.6458\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.5719 - accuracy: 0.7708 - val_loss: 0.8881 - val_accuracy: 0.7250\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.5086 - accuracy: 0.7729 - val_loss: 0.9002 - val_accuracy: 0.6625\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.4637 - accuracy: 0.7990 - val_loss: 1.1227 - val_accuracy: 0.6750\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.4136 - accuracy: 0.8094 - val_loss: 1.0372 - val_accuracy: 0.6583\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.3687 - accuracy: 0.8542 - val_loss: 1.2142 - val_accuracy: 0.6375\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.3437 - accuracy: 0.8542 - val_loss: 1.3638 - val_accuracy: 0.6167\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.3094 - accuracy: 0.8698 - val_loss: 1.4436 - val_accuracy: 0.6500\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2960 - accuracy: 0.8844 - val_loss: 1.3680 - val_accuracy: 0.6458\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2820 - accuracy: 0.8948 - val_loss: 1.4532 - val_accuracy: 0.6500\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.2148 - accuracy: 0.9260 - val_loss: 1.8828 - val_accuracy: 0.6458\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2082 - accuracy: 0.9167 - val_loss: 1.5469 - val_accuracy: 0.6583\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.2108 - accuracy: 0.9281 - val_loss: 1.6684 - val_accuracy: 0.6500\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1708 - accuracy: 0.9385 - val_loss: 1.5489 - val_accuracy: 0.6750\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1387 - accuracy: 0.9552 - val_loss: 1.7367 - val_accuracy: 0.6417\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1055 - accuracy: 0.9646 - val_loss: 2.1382 - val_accuracy: 0.6667\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1082 - accuracy: 0.9635 - val_loss: 2.0642 - val_accuracy: 0.6667\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1033 - accuracy: 0.9583 - val_loss: 2.1353 - val_accuracy: 0.6375\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1123 - accuracy: 0.9604 - val_loss: 1.8658 - val_accuracy: 0.6750\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1015 - accuracy: 0.9656 - val_loss: 2.0456 - val_accuracy: 0.6708\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1017 - accuracy: 0.9698 - val_loss: 2.0452 - val_accuracy: 0.6542\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1130 - accuracy: 0.9573 - val_loss: 1.8056 - val_accuracy: 0.6292\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0973 - accuracy: 0.9698 - val_loss: 1.8150 - val_accuracy: 0.6500\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0871 - accuracy: 0.9708 - val_loss: 2.3301 - val_accuracy: 0.6000\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0922 - accuracy: 0.9667 - val_loss: 1.8431 - val_accuracy: 0.6417\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 2.0825 - val_accuracy: 0.6583\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0705 - accuracy: 0.9823 - val_loss: 2.1890 - val_accuracy: 0.6417\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0437 - accuracy: 0.9875 - val_loss: 2.4408 - val_accuracy: 0.6625\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0436 - accuracy: 0.9844 - val_loss: 2.7855 - val_accuracy: 0.6750\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0578 - accuracy: 0.9833 - val_loss: 2.4964 - val_accuracy: 0.6917\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.0508 - accuracy: 0.9802 - val_loss: 2.4431 - val_accuracy: 0.6792\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0762 - accuracy: 0.9771 - val_loss: 2.1975 - val_accuracy: 0.6875\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0623 - accuracy: 0.9802 - val_loss: 2.1212 - val_accuracy: 0.6958\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0482 - accuracy: 0.9865 - val_loss: 2.3578 - val_accuracy: 0.6875\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 2.6661 - val_accuracy: 0.6750\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 2.3242 - val_accuracy: 0.7000\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0780 - accuracy: 0.9708 - val_loss: 2.3103 - val_accuracy: 0.7125\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0862 - accuracy: 0.9719 - val_loss: 2.3151 - val_accuracy: 0.6500\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0785 - accuracy: 0.9740 - val_loss: 1.9301 - val_accuracy: 0.6542\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 2.2104 - val_accuracy: 0.6875\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0307 - accuracy: 0.9917 - val_loss: 2.4909 - val_accuracy: 0.6958\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0450 - accuracy: 0.9823 - val_loss: 2.5719 - val_accuracy: 0.6917\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0355 - accuracy: 0.9875 - val_loss: 2.7262 - val_accuracy: 0.6792\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0347 - accuracy: 0.9875 - val_loss: 2.7114 - val_accuracy: 0.6542\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 2.7746 - val_accuracy: 0.6792\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 2.7462 - val_accuracy: 0.6875\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0374 - accuracy: 0.9865 - val_loss: 2.7934 - val_accuracy: 0.7042\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0747 - accuracy: 0.9760 - val_loss: 2.6846 - val_accuracy: 0.7167\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0524 - accuracy: 0.9802 - val_loss: 2.2858 - val_accuracy: 0.6625\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 2.2744 - val_accuracy: 0.6458\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0329 - accuracy: 0.9906 - val_loss: 2.6604 - val_accuracy: 0.6708\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0380 - accuracy: 0.9906 - val_loss: 2.3091 - val_accuracy: 0.6792\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0402 - accuracy: 0.9865 - val_loss: 2.5230 - val_accuracy: 0.6833\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0295 - accuracy: 0.9917 - val_loss: 2.4689 - val_accuracy: 0.7000\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0448 - accuracy: 0.9885 - val_loss: 2.2596 - val_accuracy: 0.6583\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0503 - accuracy: 0.9792 - val_loss: 2.3036 - val_accuracy: 0.6292\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.72      0.75       169\n",
            "           1       0.25      0.33      0.29        27\n",
            "           2       0.43      0.45      0.44        44\n",
            "\n",
            "    accuracy                           0.63       240\n",
            "   macro avg       0.48      0.50      0.49       240\n",
            "weighted avg       0.65      0.63      0.64       240\n",
            "\n",
            "Akurasi pada data uji: 0.6291666626930237\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 7s 112ms/step - loss: 0.9821 - accuracy: 0.6521 - val_loss: 0.8201 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.8331 - accuracy: 0.6833 - val_loss: 0.8045 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.7899 - accuracy: 0.6833 - val_loss: 0.7911 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.7360 - accuracy: 0.6854 - val_loss: 0.8115 - val_accuracy: 0.6875\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.6765 - accuracy: 0.7271 - val_loss: 0.8193 - val_accuracy: 0.6750\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.5815 - accuracy: 0.7604 - val_loss: 0.8278 - val_accuracy: 0.7083\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.5075 - accuracy: 0.7927 - val_loss: 0.8997 - val_accuracy: 0.6583\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.4648 - accuracy: 0.8052 - val_loss: 1.0117 - val_accuracy: 0.6667\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.4063 - accuracy: 0.8313 - val_loss: 1.1111 - val_accuracy: 0.6500\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3725 - accuracy: 0.8635 - val_loss: 1.1395 - val_accuracy: 0.6042\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.3027 - accuracy: 0.8948 - val_loss: 1.3549 - val_accuracy: 0.5792\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.3001 - accuracy: 0.8802 - val_loss: 1.3116 - val_accuracy: 0.5833\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2917 - accuracy: 0.8875 - val_loss: 1.4338 - val_accuracy: 0.5625\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.2481 - accuracy: 0.8969 - val_loss: 1.7597 - val_accuracy: 0.5917\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.2920 - accuracy: 0.8792 - val_loss: 1.2750 - val_accuracy: 0.6542\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.2159 - accuracy: 0.9198 - val_loss: 1.6675 - val_accuracy: 0.5458\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.2160 - accuracy: 0.9135 - val_loss: 1.5319 - val_accuracy: 0.6292\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.2327 - accuracy: 0.9031 - val_loss: 1.6477 - val_accuracy: 0.5042\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1683 - accuracy: 0.9469 - val_loss: 1.9600 - val_accuracy: 0.6000\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1570 - accuracy: 0.9427 - val_loss: 1.4734 - val_accuracy: 0.6792\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: 1.8182 - val_accuracy: 0.6083\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1225 - accuracy: 0.9563 - val_loss: 1.8108 - val_accuracy: 0.6583\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0923 - accuracy: 0.9688 - val_loss: 2.0707 - val_accuracy: 0.5958\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0975 - accuracy: 0.9677 - val_loss: 2.0002 - val_accuracy: 0.6500\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0665 - accuracy: 0.9781 - val_loss: 2.4115 - val_accuracy: 0.6542\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.1064 - accuracy: 0.9594 - val_loss: 1.7362 - val_accuracy: 0.6500\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1068 - accuracy: 0.9604 - val_loss: 2.0827 - val_accuracy: 0.6250\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0634 - accuracy: 0.9833 - val_loss: 2.1484 - val_accuracy: 0.6042\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0632 - accuracy: 0.9823 - val_loss: 2.2123 - val_accuracy: 0.6083\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0688 - accuracy: 0.9781 - val_loss: 2.3694 - val_accuracy: 0.6000\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0972 - accuracy: 0.9677 - val_loss: 2.0087 - val_accuracy: 0.6708\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1075 - accuracy: 0.9604 - val_loss: 1.8296 - val_accuracy: 0.6708\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0694 - accuracy: 0.9750 - val_loss: 2.4221 - val_accuracy: 0.6458\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0640 - accuracy: 0.9760 - val_loss: 2.3346 - val_accuracy: 0.6542\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.1019 - accuracy: 0.9677 - val_loss: 1.8669 - val_accuracy: 0.6708\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0989 - accuracy: 0.9656 - val_loss: 2.0774 - val_accuracy: 0.6708\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0594 - accuracy: 0.9802 - val_loss: 2.2341 - val_accuracy: 0.6583\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0477 - accuracy: 0.9823 - val_loss: 2.6004 - val_accuracy: 0.6042\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0542 - accuracy: 0.9812 - val_loss: 2.2291 - val_accuracy: 0.6708\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 2.6342 - val_accuracy: 0.6375\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0595 - accuracy: 0.9844 - val_loss: 2.2673 - val_accuracy: 0.6458\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0320 - accuracy: 0.9948 - val_loss: 2.4424 - val_accuracy: 0.6583\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.0502 - accuracy: 0.9865 - val_loss: 2.3348 - val_accuracy: 0.6333\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.0470 - accuracy: 0.9833 - val_loss: 2.5331 - val_accuracy: 0.6542\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 2.6220 - val_accuracy: 0.6500\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0696 - accuracy: 0.9844 - val_loss: 2.0124 - val_accuracy: 0.6375\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0455 - accuracy: 0.9865 - val_loss: 2.0024 - val_accuracy: 0.6875\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0432 - accuracy: 0.9823 - val_loss: 2.0980 - val_accuracy: 0.6333\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 2.4013 - val_accuracy: 0.6375\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 2.6738 - val_accuracy: 0.6542\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 2.6125 - val_accuracy: 0.6375\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.0600 - accuracy: 0.9854 - val_loss: 2.4096 - val_accuracy: 0.6708\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 0.0448 - accuracy: 0.9854 - val_loss: 2.3416 - val_accuracy: 0.6583\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0414 - accuracy: 0.9906 - val_loss: 2.4886 - val_accuracy: 0.6333\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 2.7392 - val_accuracy: 0.6292\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 2.5803 - val_accuracy: 0.6417\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 2.4508 - val_accuracy: 0.6292\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 2.5150 - val_accuracy: 0.6208\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0398 - accuracy: 0.9885 - val_loss: 2.5008 - val_accuracy: 0.6500\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.0478 - accuracy: 0.9823 - val_loss: 2.3765 - val_accuracy: 0.6833\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.82      0.80       169\n",
            "           1       0.32      0.22      0.26        27\n",
            "           2       0.46      0.43      0.45        44\n",
            "\n",
            "    accuracy                           0.68       240\n",
            "   macro avg       0.52      0.49      0.50       240\n",
            "weighted avg       0.66      0.68      0.67       240\n",
            "\n",
            "Akurasi pada data uji: 0.6833333373069763\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 5s 109ms/step - loss: 0.9299 - accuracy: 0.6656 - val_loss: 0.8035 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.8227 - accuracy: 0.6833 - val_loss: 0.7898 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.7900 - accuracy: 0.6833 - val_loss: 0.7873 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.7368 - accuracy: 0.6833 - val_loss: 0.8026 - val_accuracy: 0.7042\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.6955 - accuracy: 0.7063 - val_loss: 0.8136 - val_accuracy: 0.6792\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.6445 - accuracy: 0.7260 - val_loss: 0.9027 - val_accuracy: 0.6917\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.5701 - accuracy: 0.7740 - val_loss: 0.8388 - val_accuracy: 0.7000\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.4971 - accuracy: 0.7937 - val_loss: 0.8484 - val_accuracy: 0.7083\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4317 - accuracy: 0.8354 - val_loss: 1.0227 - val_accuracy: 0.6917\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.3528 - accuracy: 0.8677 - val_loss: 1.1232 - val_accuracy: 0.6417\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.3030 - accuracy: 0.8750 - val_loss: 1.1936 - val_accuracy: 0.6833\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.2457 - accuracy: 0.9042 - val_loss: 1.2406 - val_accuracy: 0.6625\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.2276 - accuracy: 0.9198 - val_loss: 1.2561 - val_accuracy: 0.6833\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1929 - accuracy: 0.9271 - val_loss: 1.4761 - val_accuracy: 0.6792\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1687 - accuracy: 0.9406 - val_loss: 1.5877 - val_accuracy: 0.6875\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1477 - accuracy: 0.9458 - val_loss: 1.5483 - val_accuracy: 0.6750\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1509 - accuracy: 0.9490 - val_loss: 1.5554 - val_accuracy: 0.7042\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1174 - accuracy: 0.9563 - val_loss: 1.7727 - val_accuracy: 0.6792\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1181 - accuracy: 0.9625 - val_loss: 1.8991 - val_accuracy: 0.6708\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0987 - accuracy: 0.9635 - val_loss: 1.9463 - val_accuracy: 0.6833\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.0919 - accuracy: 0.9729 - val_loss: 1.7126 - val_accuracy: 0.6917\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1026 - accuracy: 0.9625 - val_loss: 1.7573 - val_accuracy: 0.6708\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0941 - accuracy: 0.9656 - val_loss: 1.6849 - val_accuracy: 0.6708\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0682 - accuracy: 0.9750 - val_loss: 1.8758 - val_accuracy: 0.6833\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1006 - accuracy: 0.9646 - val_loss: 1.7851 - val_accuracy: 0.6792\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0856 - accuracy: 0.9688 - val_loss: 1.7726 - val_accuracy: 0.7000\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 1.9842 - val_accuracy: 0.6875\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0514 - accuracy: 0.9812 - val_loss: 2.2946 - val_accuracy: 0.6917\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0529 - accuracy: 0.9792 - val_loss: 2.2673 - val_accuracy: 0.6708\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 0.0791 - accuracy: 0.9729 - val_loss: 2.0020 - val_accuracy: 0.6542\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.0661 - accuracy: 0.9792 - val_loss: 1.8875 - val_accuracy: 0.6625\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 1.9749 - val_accuracy: 0.6417\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0536 - accuracy: 0.9781 - val_loss: 1.9986 - val_accuracy: 0.7000\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0700 - accuracy: 0.9781 - val_loss: 1.8397 - val_accuracy: 0.6667\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0612 - accuracy: 0.9792 - val_loss: 1.8253 - val_accuracy: 0.6750\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0520 - accuracy: 0.9792 - val_loss: 2.1537 - val_accuracy: 0.6542\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 2.3381 - val_accuracy: 0.6958\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0729 - accuracy: 0.9719 - val_loss: 2.0880 - val_accuracy: 0.6917\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.0589 - accuracy: 0.9771 - val_loss: 1.9813 - val_accuracy: 0.6625\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0602 - accuracy: 0.9760 - val_loss: 2.0202 - val_accuracy: 0.6583\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 2.1595 - val_accuracy: 0.6958\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0430 - accuracy: 0.9823 - val_loss: 2.4485 - val_accuracy: 0.6958\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0429 - accuracy: 0.9833 - val_loss: 2.2960 - val_accuracy: 0.6792\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 2.1755 - val_accuracy: 0.7000\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0510 - accuracy: 0.9865 - val_loss: 2.2371 - val_accuracy: 0.7167\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 2.2351 - val_accuracy: 0.7125\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 2.4190 - val_accuracy: 0.6875\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 2.4825 - val_accuracy: 0.7125\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 2.4468 - val_accuracy: 0.7125\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 2.5866 - val_accuracy: 0.6792\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.0605 - accuracy: 0.9771 - val_loss: 2.3841 - val_accuracy: 0.6583\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0398 - accuracy: 0.9844 - val_loss: 2.3490 - val_accuracy: 0.6583\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0497 - accuracy: 0.9781 - val_loss: 2.3207 - val_accuracy: 0.6625\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 2.2781 - val_accuracy: 0.6625\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0355 - accuracy: 0.9865 - val_loss: 2.2592 - val_accuracy: 0.6708\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 2.1943 - val_accuracy: 0.6958\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0257 - accuracy: 0.9948 - val_loss: 2.2755 - val_accuracy: 0.6875\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 2.5141 - val_accuracy: 0.6667\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 2.6034 - val_accuracy: 0.6583\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0394 - accuracy: 0.9875 - val_loss: 2.4229 - val_accuracy: 0.6875\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80       169\n",
            "           1       0.33      0.33      0.33        27\n",
            "           2       0.50      0.39      0.44        44\n",
            "\n",
            "    accuracy                           0.69       240\n",
            "   macro avg       0.54      0.51      0.52       240\n",
            "weighted avg       0.68      0.69      0.68       240\n",
            "\n",
            "Akurasi pada data uji: 0.6875\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 6s 110ms/step - loss: 0.9674 - accuracy: 0.6354 - val_loss: 0.8444 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.8317 - accuracy: 0.6833 - val_loss: 0.7930 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.7895 - accuracy: 0.6833 - val_loss: 0.7891 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.7353 - accuracy: 0.6844 - val_loss: 0.8164 - val_accuracy: 0.6958\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.6521 - accuracy: 0.7208 - val_loss: 0.8663 - val_accuracy: 0.7083\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.5655 - accuracy: 0.7656 - val_loss: 0.8629 - val_accuracy: 0.6917\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.5076 - accuracy: 0.7927 - val_loss: 0.8938 - val_accuracy: 0.6875\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.4407 - accuracy: 0.8115 - val_loss: 1.1095 - val_accuracy: 0.6667\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4034 - accuracy: 0.8177 - val_loss: 1.2595 - val_accuracy: 0.6875\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.3877 - accuracy: 0.8313 - val_loss: 1.1712 - val_accuracy: 0.6292\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.3688 - accuracy: 0.8500 - val_loss: 1.3623 - val_accuracy: 0.6333\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.3517 - accuracy: 0.8469 - val_loss: 1.3387 - val_accuracy: 0.6458\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.3021 - accuracy: 0.8729 - val_loss: 1.5498 - val_accuracy: 0.6500\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.2839 - accuracy: 0.8833 - val_loss: 1.7183 - val_accuracy: 0.6667\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.3276 - accuracy: 0.8729 - val_loss: 1.4184 - val_accuracy: 0.6167\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.2747 - accuracy: 0.8948 - val_loss: 1.5523 - val_accuracy: 0.6583\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2346 - accuracy: 0.9062 - val_loss: 1.8142 - val_accuracy: 0.6500\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.1938 - accuracy: 0.9312 - val_loss: 1.8854 - val_accuracy: 0.6375\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.2624 - accuracy: 0.8990 - val_loss: 1.3866 - val_accuracy: 0.6583\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.2000 - accuracy: 0.9302 - val_loss: 2.0605 - val_accuracy: 0.6500\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.1637 - accuracy: 0.9396 - val_loss: 2.0198 - val_accuracy: 0.6083\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.1777 - accuracy: 0.9302 - val_loss: 1.7664 - val_accuracy: 0.6333\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1454 - accuracy: 0.9448 - val_loss: 2.1375 - val_accuracy: 0.5958\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1374 - accuracy: 0.9458 - val_loss: 2.0712 - val_accuracy: 0.6667\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1768 - accuracy: 0.9385 - val_loss: 1.6509 - val_accuracy: 0.6583\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1363 - accuracy: 0.9469 - val_loss: 1.8473 - val_accuracy: 0.6833\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.1006 - accuracy: 0.9646 - val_loss: 2.2893 - val_accuracy: 0.6458\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1003 - accuracy: 0.9688 - val_loss: 2.1623 - val_accuracy: 0.6833\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1099 - accuracy: 0.9656 - val_loss: 2.2930 - val_accuracy: 0.6333\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0887 - accuracy: 0.9635 - val_loss: 2.0567 - val_accuracy: 0.6542\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0967 - accuracy: 0.9646 - val_loss: 2.0541 - val_accuracy: 0.6917\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 2.1483 - val_accuracy: 0.6417\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 2.2450 - val_accuracy: 0.6458\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0624 - accuracy: 0.9823 - val_loss: 2.4853 - val_accuracy: 0.6083\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 2.2830 - val_accuracy: 0.6875\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 2.6229 - val_accuracy: 0.6583\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0680 - accuracy: 0.9729 - val_loss: 2.3436 - val_accuracy: 0.6667\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0681 - accuracy: 0.9802 - val_loss: 2.2841 - val_accuracy: 0.6542\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0496 - accuracy: 0.9802 - val_loss: 2.3165 - val_accuracy: 0.6458\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0778 - accuracy: 0.9729 - val_loss: 2.4144 - val_accuracy: 0.6208\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0732 - accuracy: 0.9781 - val_loss: 2.2544 - val_accuracy: 0.6208\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0483 - accuracy: 0.9833 - val_loss: 2.3347 - val_accuracy: 0.6500\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0597 - accuracy: 0.9802 - val_loss: 2.3304 - val_accuracy: 0.6375\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0631 - accuracy: 0.9802 - val_loss: 2.1115 - val_accuracy: 0.6958\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.0696 - accuracy: 0.9729 - val_loss: 2.1496 - val_accuracy: 0.6667\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0586 - accuracy: 0.9792 - val_loss: 2.1820 - val_accuracy: 0.6792\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0470 - accuracy: 0.9865 - val_loss: 2.5693 - val_accuracy: 0.6792\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0435 - accuracy: 0.9844 - val_loss: 2.7588 - val_accuracy: 0.6000\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 2.5841 - val_accuracy: 0.6250\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0557 - accuracy: 0.9812 - val_loss: 2.8434 - val_accuracy: 0.6292\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0469 - accuracy: 0.9896 - val_loss: 2.5968 - val_accuracy: 0.6583\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0596 - accuracy: 0.9833 - val_loss: 2.7819 - val_accuracy: 0.6042\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 2.5251 - val_accuracy: 0.6708\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 2.5807 - val_accuracy: 0.6417\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.0536 - accuracy: 0.9833 - val_loss: 2.3309 - val_accuracy: 0.6917\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 2.3252 - val_accuracy: 0.6833\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0442 - accuracy: 0.9875 - val_loss: 2.5725 - val_accuracy: 0.6375\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 2.6392 - val_accuracy: 0.6625\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0602 - accuracy: 0.9792 - val_loss: 2.3246 - val_accuracy: 0.6833\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 2.2995 - val_accuracy: 0.6500\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.78      0.77       169\n",
            "           1       0.24      0.37      0.29        27\n",
            "           2       0.52      0.32      0.39        44\n",
            "\n",
            "    accuracy                           0.65       240\n",
            "   macro avg       0.51      0.49      0.49       240\n",
            "weighted avg       0.66      0.65      0.65       240\n",
            "\n",
            "Akurasi pada data uji: 0.6499999761581421\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 7s 172ms/step - loss: 0.9184 - accuracy: 0.6521 - val_loss: 0.8032 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 0.8064 - accuracy: 0.6833 - val_loss: 0.7847 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.7504 - accuracy: 0.6854 - val_loss: 0.8157 - val_accuracy: 0.6792\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.6803 - accuracy: 0.7135 - val_loss: 0.8253 - val_accuracy: 0.7083\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.6075 - accuracy: 0.7510 - val_loss: 0.8691 - val_accuracy: 0.7042\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.5434 - accuracy: 0.7854 - val_loss: 0.8526 - val_accuracy: 0.6792\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.4892 - accuracy: 0.7969 - val_loss: 0.9257 - val_accuracy: 0.7000\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.4223 - accuracy: 0.8208 - val_loss: 1.0842 - val_accuracy: 0.6625\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.4147 - accuracy: 0.8219 - val_loss: 1.0318 - val_accuracy: 0.6542\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.3471 - accuracy: 0.8458 - val_loss: 1.2263 - val_accuracy: 0.6292\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 0.3745 - accuracy: 0.8302 - val_loss: 1.1720 - val_accuracy: 0.6292\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3095 - accuracy: 0.8635 - val_loss: 1.3463 - val_accuracy: 0.6458\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.2823 - accuracy: 0.8958 - val_loss: 1.4522 - val_accuracy: 0.5833\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3029 - accuracy: 0.8771 - val_loss: 1.4290 - val_accuracy: 0.6500\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.2525 - accuracy: 0.8969 - val_loss: 1.5313 - val_accuracy: 0.5917\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2389 - accuracy: 0.9125 - val_loss: 1.6607 - val_accuracy: 0.6500\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2314 - accuracy: 0.9135 - val_loss: 1.6019 - val_accuracy: 0.6250\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 0.2451 - accuracy: 0.9073 - val_loss: 1.5051 - val_accuracy: 0.6542\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.1825 - accuracy: 0.9333 - val_loss: 1.7569 - val_accuracy: 0.6417\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.1590 - accuracy: 0.9427 - val_loss: 1.7637 - val_accuracy: 0.6625\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1522 - accuracy: 0.9438 - val_loss: 1.6312 - val_accuracy: 0.6542\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1499 - accuracy: 0.9469 - val_loss: 1.5513 - val_accuracy: 0.6542\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1467 - accuracy: 0.9583 - val_loss: 1.8553 - val_accuracy: 0.6542\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1466 - accuracy: 0.9521 - val_loss: 1.8289 - val_accuracy: 0.6500\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1004 - accuracy: 0.9646 - val_loss: 1.8962 - val_accuracy: 0.6542\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1188 - accuracy: 0.9604 - val_loss: 2.1705 - val_accuracy: 0.6750\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1525 - accuracy: 0.9438 - val_loss: 1.5268 - val_accuracy: 0.6667\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.1218 - accuracy: 0.9615 - val_loss: 1.9252 - val_accuracy: 0.6292\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0762 - accuracy: 0.9750 - val_loss: 2.0658 - val_accuracy: 0.6417\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0565 - accuracy: 0.9823 - val_loss: 2.2976 - val_accuracy: 0.6708\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0625 - accuracy: 0.9812 - val_loss: 2.3358 - val_accuracy: 0.6667\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0713 - accuracy: 0.9781 - val_loss: 2.2552 - val_accuracy: 0.6458\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1136 - accuracy: 0.9688 - val_loss: 2.1359 - val_accuracy: 0.6583\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 2.0089 - val_accuracy: 0.6583\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0873 - accuracy: 0.9656 - val_loss: 1.9990 - val_accuracy: 0.6458\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0491 - accuracy: 0.9865 - val_loss: 2.4399 - val_accuracy: 0.6500\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0692 - accuracy: 0.9802 - val_loss: 2.4241 - val_accuracy: 0.6583\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0804 - accuracy: 0.9740 - val_loss: 2.1495 - val_accuracy: 0.6875\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0710 - accuracy: 0.9781 - val_loss: 1.9503 - val_accuracy: 0.6792\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0552 - accuracy: 0.9812 - val_loss: 2.2285 - val_accuracy: 0.6958\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 2.3764 - val_accuracy: 0.7042\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0644 - accuracy: 0.9760 - val_loss: 2.2894 - val_accuracy: 0.6750\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0804 - accuracy: 0.9750 - val_loss: 2.2155 - val_accuracy: 0.6583\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0785 - accuracy: 0.9750 - val_loss: 2.0092 - val_accuracy: 0.6542\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0514 - accuracy: 0.9854 - val_loss: 2.1942 - val_accuracy: 0.6917\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 2.4540 - val_accuracy: 0.6375\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0548 - accuracy: 0.9833 - val_loss: 2.3665 - val_accuracy: 0.6625\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0668 - accuracy: 0.9802 - val_loss: 2.0506 - val_accuracy: 0.6500\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 1.8703 - val_accuracy: 0.6792\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0537 - accuracy: 0.9854 - val_loss: 1.7699 - val_accuracy: 0.6833\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 2.1641 - val_accuracy: 0.6958\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0381 - accuracy: 0.9865 - val_loss: 2.2550 - val_accuracy: 0.6833\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.0456 - accuracy: 0.9875 - val_loss: 2.1900 - val_accuracy: 0.6625\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 2.5461 - val_accuracy: 0.6583\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 2.3910 - val_accuracy: 0.6458\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0456 - accuracy: 0.9875 - val_loss: 2.2965 - val_accuracy: 0.6792\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: 2.1429 - val_accuracy: 0.6792\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0544 - accuracy: 0.9812 - val_loss: 2.3576 - val_accuracy: 0.7125\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0682 - accuracy: 0.9792 - val_loss: 2.0346 - val_accuracy: 0.7208\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0520 - accuracy: 0.9812 - val_loss: 1.9985 - val_accuracy: 0.6917\n",
            "8/8 [==============================] - 1s 19ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.80       169\n",
            "           1       0.40      0.30      0.34        27\n",
            "           2       0.49      0.39      0.43        44\n",
            "\n",
            "    accuracy                           0.69       240\n",
            "   macro avg       0.55      0.51      0.52       240\n",
            "weighted avg       0.67      0.69      0.68       240\n",
            "\n",
            "Akurasi pada data uji: 0.6916666626930237\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 6s 113ms/step - loss: 0.9382 - accuracy: 0.6750 - val_loss: 0.7951 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.8238 - accuracy: 0.6833 - val_loss: 0.7895 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.7736 - accuracy: 0.6833 - val_loss: 0.7899 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.7138 - accuracy: 0.6990 - val_loss: 0.7978 - val_accuracy: 0.6875\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.6184 - accuracy: 0.7417 - val_loss: 0.7902 - val_accuracy: 0.7083\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.5317 - accuracy: 0.7823 - val_loss: 0.8771 - val_accuracy: 0.6875\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.5131 - accuracy: 0.7812 - val_loss: 0.8764 - val_accuracy: 0.7167\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.4569 - accuracy: 0.8115 - val_loss: 1.1293 - val_accuracy: 0.6625\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.3825 - accuracy: 0.8313 - val_loss: 1.1728 - val_accuracy: 0.6792\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.3688 - accuracy: 0.8542 - val_loss: 1.2487 - val_accuracy: 0.6458\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3160 - accuracy: 0.8792 - val_loss: 1.2959 - val_accuracy: 0.6375\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.2930 - accuracy: 0.8833 - val_loss: 1.6359 - val_accuracy: 0.6333\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.2777 - accuracy: 0.8938 - val_loss: 1.5583 - val_accuracy: 0.6167\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.2530 - accuracy: 0.8979 - val_loss: 1.6125 - val_accuracy: 0.5958\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2527 - accuracy: 0.9052 - val_loss: 1.6014 - val_accuracy: 0.6583\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.2387 - accuracy: 0.9031 - val_loss: 1.4806 - val_accuracy: 0.6083\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2089 - accuracy: 0.9198 - val_loss: 1.5490 - val_accuracy: 0.6458\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1743 - accuracy: 0.9312 - val_loss: 1.6652 - val_accuracy: 0.5958\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1676 - accuracy: 0.9375 - val_loss: 1.6037 - val_accuracy: 0.6583\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1674 - accuracy: 0.9375 - val_loss: 1.7546 - val_accuracy: 0.6500\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.1109 - accuracy: 0.9615 - val_loss: 2.0930 - val_accuracy: 0.6125\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1211 - accuracy: 0.9594 - val_loss: 1.9579 - val_accuracy: 0.6833\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1132 - accuracy: 0.9625 - val_loss: 1.6649 - val_accuracy: 0.6708\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 0.1354 - accuracy: 0.9531 - val_loss: 1.9027 - val_accuracy: 0.6792\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.1155 - accuracy: 0.9667 - val_loss: 1.7134 - val_accuracy: 0.6583\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0795 - accuracy: 0.9750 - val_loss: 1.7733 - val_accuracy: 0.6583\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0619 - accuracy: 0.9854 - val_loss: 2.1377 - val_accuracy: 0.6375\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0539 - accuracy: 0.9854 - val_loss: 2.2316 - val_accuracy: 0.6375\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0749 - accuracy: 0.9760 - val_loss: 2.1433 - val_accuracy: 0.6458\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0632 - accuracy: 0.9771 - val_loss: 2.1486 - val_accuracy: 0.6417\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0787 - accuracy: 0.9719 - val_loss: 2.1169 - val_accuracy: 0.6042\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0995 - accuracy: 0.9646 - val_loss: 1.9143 - val_accuracy: 0.6417\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 0.0554 - accuracy: 0.9812 - val_loss: 2.0624 - val_accuracy: 0.6417\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0636 - accuracy: 0.9802 - val_loss: 2.0323 - val_accuracy: 0.6375\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0631 - accuracy: 0.9781 - val_loss: 1.8870 - val_accuracy: 0.6458\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0441 - accuracy: 0.9854 - val_loss: 2.2419 - val_accuracy: 0.6667\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 2.4964 - val_accuracy: 0.6667\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 2.2504 - val_accuracy: 0.6625\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0449 - accuracy: 0.9885 - val_loss: 2.2565 - val_accuracy: 0.6542\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0354 - accuracy: 0.9917 - val_loss: 2.4371 - val_accuracy: 0.6417\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 2.6229 - val_accuracy: 0.6708\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 2.5287 - val_accuracy: 0.6750\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0483 - accuracy: 0.9833 - val_loss: 2.3370 - val_accuracy: 0.6583\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0581 - accuracy: 0.9792 - val_loss: 1.9303 - val_accuracy: 0.6458\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0602 - accuracy: 0.9781 - val_loss: 1.9929 - val_accuracy: 0.6417\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 2.0099 - val_accuracy: 0.6333\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 2.1502 - val_accuracy: 0.6458\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0648 - accuracy: 0.9823 - val_loss: 2.1857 - val_accuracy: 0.5958\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 2.3496 - val_accuracy: 0.6333\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 2.3131 - val_accuracy: 0.6375\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 2.4127 - val_accuracy: 0.6333\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.0476 - accuracy: 0.9854 - val_loss: 2.3228 - val_accuracy: 0.6417\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.0638 - accuracy: 0.9781 - val_loss: 2.0154 - val_accuracy: 0.6875\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0602 - accuracy: 0.9865 - val_loss: 1.9937 - val_accuracy: 0.7083\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0564 - accuracy: 0.9865 - val_loss: 1.9312 - val_accuracy: 0.6542\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0343 - accuracy: 0.9917 - val_loss: 2.1792 - val_accuracy: 0.6375\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 2.3874 - val_accuracy: 0.6500\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 2.3863 - val_accuracy: 0.6750\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 2.3962 - val_accuracy: 0.6375\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0346 - accuracy: 0.9875 - val_loss: 2.4767 - val_accuracy: 0.6250\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.72      0.74       169\n",
            "           1       0.29      0.37      0.32        27\n",
            "           2       0.40      0.41      0.40        44\n",
            "\n",
            "    accuracy                           0.62       240\n",
            "   macro avg       0.48      0.50      0.49       240\n",
            "weighted avg       0.64      0.62      0.63       240\n",
            "\n",
            "Akurasi pada data uji: 0.625\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 8s 195ms/step - loss: 0.9591 - accuracy: 0.6135 - val_loss: 0.7984 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.8163 - accuracy: 0.6833 - val_loss: 0.8057 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.7823 - accuracy: 0.6833 - val_loss: 0.8230 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.7275 - accuracy: 0.6812 - val_loss: 0.8257 - val_accuracy: 0.7083\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.6481 - accuracy: 0.7177 - val_loss: 0.8460 - val_accuracy: 0.7042\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.5463 - accuracy: 0.7708 - val_loss: 0.9868 - val_accuracy: 0.7125\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.5290 - accuracy: 0.7771 - val_loss: 0.8404 - val_accuracy: 0.6833\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.4683 - accuracy: 0.7958 - val_loss: 1.0592 - val_accuracy: 0.6042\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.4409 - accuracy: 0.8198 - val_loss: 1.2069 - val_accuracy: 0.7042\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.3788 - accuracy: 0.8354 - val_loss: 1.2404 - val_accuracy: 0.6458\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 0.3243 - accuracy: 0.8573 - val_loss: 1.5086 - val_accuracy: 0.6458\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3144 - accuracy: 0.8656 - val_loss: 1.3802 - val_accuracy: 0.6583\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3052 - accuracy: 0.8729 - val_loss: 1.2964 - val_accuracy: 0.6667\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2954 - accuracy: 0.8771 - val_loss: 1.5966 - val_accuracy: 0.6375\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.2739 - accuracy: 0.8938 - val_loss: 1.4965 - val_accuracy: 0.6500\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2346 - accuracy: 0.9219 - val_loss: 1.6100 - val_accuracy: 0.6083\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.2019 - accuracy: 0.9198 - val_loss: 1.6798 - val_accuracy: 0.6417\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.2065 - accuracy: 0.9219 - val_loss: 1.6960 - val_accuracy: 0.6542\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.1951 - accuracy: 0.9240 - val_loss: 1.5930 - val_accuracy: 0.6625\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.1574 - accuracy: 0.9479 - val_loss: 2.0685 - val_accuracy: 0.6125\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1758 - accuracy: 0.9417 - val_loss: 1.7633 - val_accuracy: 0.6208\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1556 - accuracy: 0.9500 - val_loss: 1.8400 - val_accuracy: 0.6583\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1093 - accuracy: 0.9615 - val_loss: 2.0052 - val_accuracy: 0.6708\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1324 - accuracy: 0.9604 - val_loss: 1.7621 - val_accuracy: 0.6583\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1074 - accuracy: 0.9604 - val_loss: 2.0315 - val_accuracy: 0.6667\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0766 - accuracy: 0.9750 - val_loss: 2.1516 - val_accuracy: 0.6500\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 0.0897 - accuracy: 0.9688 - val_loss: 1.9682 - val_accuracy: 0.6500\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0967 - accuracy: 0.9677 - val_loss: 2.0593 - val_accuracy: 0.6625\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 2s 94ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 2.3052 - val_accuracy: 0.6250\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0957 - accuracy: 0.9667 - val_loss: 2.1258 - val_accuracy: 0.6875\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0962 - accuracy: 0.9729 - val_loss: 2.1210 - val_accuracy: 0.6625\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0789 - accuracy: 0.9792 - val_loss: 2.3361 - val_accuracy: 0.6917\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0763 - accuracy: 0.9750 - val_loss: 2.2272 - val_accuracy: 0.6708\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0842 - accuracy: 0.9729 - val_loss: 2.3716 - val_accuracy: 0.6542\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0697 - accuracy: 0.9760 - val_loss: 2.3479 - val_accuracy: 0.6875\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 2.3675 - val_accuracy: 0.6792\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0628 - accuracy: 0.9781 - val_loss: 2.4592 - val_accuracy: 0.6750\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0825 - accuracy: 0.9708 - val_loss: 2.2750 - val_accuracy: 0.6792\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0808 - accuracy: 0.9729 - val_loss: 2.3333 - val_accuracy: 0.6583\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1040 - accuracy: 0.9688 - val_loss: 1.8703 - val_accuracy: 0.6583\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0659 - accuracy: 0.9833 - val_loss: 2.1516 - val_accuracy: 0.6708\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0570 - accuracy: 0.9812 - val_loss: 2.2047 - val_accuracy: 0.6708\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0465 - accuracy: 0.9854 - val_loss: 2.3087 - val_accuracy: 0.6667\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 2.6435 - val_accuracy: 0.6875\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0403 - accuracy: 0.9844 - val_loss: 3.0735 - val_accuracy: 0.6417\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.0555 - accuracy: 0.9812 - val_loss: 2.7968 - val_accuracy: 0.6583\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0761 - accuracy: 0.9760 - val_loss: 2.3928 - val_accuracy: 0.6292\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0758 - accuracy: 0.9740 - val_loss: 2.1509 - val_accuracy: 0.6458\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0546 - accuracy: 0.9854 - val_loss: 2.3046 - val_accuracy: 0.6750\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0458 - accuracy: 0.9844 - val_loss: 2.3088 - val_accuracy: 0.6792\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 2.4500 - val_accuracy: 0.6542\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 2.7251 - val_accuracy: 0.6750\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 2.7881 - val_accuracy: 0.6542\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.0280 - accuracy: 0.9948 - val_loss: 2.7140 - val_accuracy: 0.6542\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 2.7583 - val_accuracy: 0.6500\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 2.7402 - val_accuracy: 0.6667\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0591 - accuracy: 0.9781 - val_loss: 3.1431 - val_accuracy: 0.6958\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0711 - accuracy: 0.9729 - val_loss: 2.3346 - val_accuracy: 0.6792\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 2.1749 - val_accuracy: 0.6500\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 2.3455 - val_accuracy: 0.6667\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.79      0.78       169\n",
            "           1       0.29      0.26      0.27        27\n",
            "           2       0.47      0.43      0.45        44\n",
            "\n",
            "    accuracy                           0.67       240\n",
            "   macro avg       0.51      0.49      0.50       240\n",
            "weighted avg       0.66      0.67      0.66       240\n",
            "\n",
            "Akurasi pada data uji: 0.6666666865348816\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 6s 112ms/step - loss: 0.9005 - accuracy: 0.6812 - val_loss: 0.8220 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.8121 - accuracy: 0.6833 - val_loss: 0.7945 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.7604 - accuracy: 0.6833 - val_loss: 0.7963 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.6873 - accuracy: 0.6979 - val_loss: 0.8074 - val_accuracy: 0.7333\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.5906 - accuracy: 0.7500 - val_loss: 0.8209 - val_accuracy: 0.6958\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.5027 - accuracy: 0.7823 - val_loss: 0.9737 - val_accuracy: 0.6958\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.4683 - accuracy: 0.7990 - val_loss: 0.9507 - val_accuracy: 0.6083\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.4340 - accuracy: 0.8177 - val_loss: 1.1009 - val_accuracy: 0.6875\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3754 - accuracy: 0.8396 - val_loss: 1.2261 - val_accuracy: 0.6750\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.3834 - accuracy: 0.8333 - val_loss: 1.1506 - val_accuracy: 0.6750\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3457 - accuracy: 0.8604 - val_loss: 1.4086 - val_accuracy: 0.6083\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2947 - accuracy: 0.8813 - val_loss: 1.5559 - val_accuracy: 0.6500\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.2747 - accuracy: 0.8865 - val_loss: 1.5022 - val_accuracy: 0.6000\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.2766 - accuracy: 0.8875 - val_loss: 1.3725 - val_accuracy: 0.6458\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2372 - accuracy: 0.9135 - val_loss: 1.5263 - val_accuracy: 0.6208\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2131 - accuracy: 0.9187 - val_loss: 1.6247 - val_accuracy: 0.6292\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.1846 - accuracy: 0.9323 - val_loss: 1.8148 - val_accuracy: 0.6583\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1574 - accuracy: 0.9438 - val_loss: 1.6522 - val_accuracy: 0.6500\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1373 - accuracy: 0.9542 - val_loss: 1.8696 - val_accuracy: 0.6708\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1228 - accuracy: 0.9552 - val_loss: 1.7595 - val_accuracy: 0.6917\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1366 - accuracy: 0.9479 - val_loss: 1.7245 - val_accuracy: 0.6917\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1046 - accuracy: 0.9656 - val_loss: 1.8399 - val_accuracy: 0.7042\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.1115 - accuracy: 0.9625 - val_loss: 1.8295 - val_accuracy: 0.6542\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.1479 - accuracy: 0.9510 - val_loss: 1.6094 - val_accuracy: 0.6833\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0950 - accuracy: 0.9698 - val_loss: 1.5865 - val_accuracy: 0.6542\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0782 - accuracy: 0.9719 - val_loss: 2.5517 - val_accuracy: 0.6958\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1163 - accuracy: 0.9656 - val_loss: 1.8656 - val_accuracy: 0.7208\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1075 - accuracy: 0.9625 - val_loss: 1.8021 - val_accuracy: 0.7000\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0819 - accuracy: 0.9740 - val_loss: 2.1772 - val_accuracy: 0.6667\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0675 - accuracy: 0.9812 - val_loss: 2.3513 - val_accuracy: 0.6917\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0722 - accuracy: 0.9771 - val_loss: 1.9480 - val_accuracy: 0.6625\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0563 - accuracy: 0.9771 - val_loss: 1.9592 - val_accuracy: 0.6833\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0584 - accuracy: 0.9802 - val_loss: 2.3484 - val_accuracy: 0.7125\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 2.4960 - val_accuracy: 0.7000\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0964 - accuracy: 0.9667 - val_loss: 2.0577 - val_accuracy: 0.6917\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0781 - accuracy: 0.9719 - val_loss: 1.8886 - val_accuracy: 0.6750\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 2.1012 - val_accuracy: 0.6542\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0471 - accuracy: 0.9833 - val_loss: 2.2712 - val_accuracy: 0.6542\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0398 - accuracy: 0.9885 - val_loss: 2.2811 - val_accuracy: 0.6792\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0394 - accuracy: 0.9885 - val_loss: 2.4923 - val_accuracy: 0.6500\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0413 - accuracy: 0.9854 - val_loss: 2.4014 - val_accuracy: 0.6500\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0567 - accuracy: 0.9844 - val_loss: 2.2904 - val_accuracy: 0.6625\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 2.1653 - val_accuracy: 0.6917\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0727 - accuracy: 0.9760 - val_loss: 2.0929 - val_accuracy: 0.7000\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0611 - accuracy: 0.9812 - val_loss: 2.1084 - val_accuracy: 0.6625\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 2.1817 - val_accuracy: 0.6833\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0422 - accuracy: 0.9833 - val_loss: 2.4030 - val_accuracy: 0.6792\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0449 - accuracy: 0.9917 - val_loss: 2.7389 - val_accuracy: 0.6625\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 2.1029 - val_accuracy: 0.6917\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 2.3139 - val_accuracy: 0.6542\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.0507 - accuracy: 0.9812 - val_loss: 2.1857 - val_accuracy: 0.6583\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0351 - accuracy: 0.9906 - val_loss: 2.1711 - val_accuracy: 0.6833\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 2.3771 - val_accuracy: 0.6708\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 2.3865 - val_accuracy: 0.6542\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 2.3588 - val_accuracy: 0.6958\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 2.5428 - val_accuracy: 0.7000\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0502 - accuracy: 0.9885 - val_loss: 2.2311 - val_accuracy: 0.6583\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0332 - accuracy: 0.9875 - val_loss: 2.4299 - val_accuracy: 0.6500\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0608 - accuracy: 0.9823 - val_loss: 2.5121 - val_accuracy: 0.6833\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0689 - accuracy: 0.9781 - val_loss: 2.2167 - val_accuracy: 0.6667\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       169\n",
            "           1       0.25      0.33      0.29        27\n",
            "           2       0.55      0.25      0.34        44\n",
            "\n",
            "    accuracy                           0.67       240\n",
            "   macro avg       0.52      0.47      0.47       240\n",
            "weighted avg       0.66      0.67      0.65       240\n",
            "\n",
            "Akurasi pada data uji: 0.6666666865348816\n",
            "Epoch 1/60\n",
            "16/16 [==============================] - 5s 113ms/step - loss: 0.9610 - accuracy: 0.6479 - val_loss: 0.8012 - val_accuracy: 0.7042\n",
            "Epoch 2/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.8226 - accuracy: 0.6833 - val_loss: 0.8183 - val_accuracy: 0.7042\n",
            "Epoch 3/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.8019 - accuracy: 0.6833 - val_loss: 0.7869 - val_accuracy: 0.7042\n",
            "Epoch 4/60\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.7464 - accuracy: 0.6844 - val_loss: 0.8028 - val_accuracy: 0.7083\n",
            "Epoch 5/60\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.6662 - accuracy: 0.7125 - val_loss: 0.8722 - val_accuracy: 0.6875\n",
            "Epoch 6/60\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.6142 - accuracy: 0.7563 - val_loss: 0.7784 - val_accuracy: 0.7208\n",
            "Epoch 7/60\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.5329 - accuracy: 0.7771 - val_loss: 0.8756 - val_accuracy: 0.7083\n",
            "Epoch 8/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.4672 - accuracy: 0.7969 - val_loss: 1.0231 - val_accuracy: 0.6958\n",
            "Epoch 9/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.4320 - accuracy: 0.8177 - val_loss: 1.1081 - val_accuracy: 0.6833\n",
            "Epoch 10/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3926 - accuracy: 0.8396 - val_loss: 1.1205 - val_accuracy: 0.6375\n",
            "Epoch 11/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3177 - accuracy: 0.8719 - val_loss: 1.4687 - val_accuracy: 0.6333\n",
            "Epoch 12/60\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.3045 - accuracy: 0.8792 - val_loss: 1.5425 - val_accuracy: 0.6375\n",
            "Epoch 13/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.2871 - accuracy: 0.8969 - val_loss: 1.4019 - val_accuracy: 0.6333\n",
            "Epoch 14/60\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.2485 - accuracy: 0.8917 - val_loss: 1.4127 - val_accuracy: 0.6292\n",
            "Epoch 15/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.2109 - accuracy: 0.9229 - val_loss: 1.5133 - val_accuracy: 0.6458\n",
            "Epoch 16/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.2015 - accuracy: 0.9208 - val_loss: 1.4612 - val_accuracy: 0.6667\n",
            "Epoch 17/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1921 - accuracy: 0.9250 - val_loss: 1.6140 - val_accuracy: 0.6542\n",
            "Epoch 18/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1538 - accuracy: 0.9427 - val_loss: 1.7695 - val_accuracy: 0.6875\n",
            "Epoch 19/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1410 - accuracy: 0.9521 - val_loss: 1.6647 - val_accuracy: 0.6583\n",
            "Epoch 20/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1265 - accuracy: 0.9594 - val_loss: 1.7389 - val_accuracy: 0.6417\n",
            "Epoch 21/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0920 - accuracy: 0.9719 - val_loss: 1.8755 - val_accuracy: 0.6542\n",
            "Epoch 22/60\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.1000 - accuracy: 0.9677 - val_loss: 2.1299 - val_accuracy: 0.7042\n",
            "Epoch 23/60\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0931 - accuracy: 0.9667 - val_loss: 1.7683 - val_accuracy: 0.6708\n",
            "Epoch 24/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0842 - accuracy: 0.9719 - val_loss: 2.1759 - val_accuracy: 0.6792\n",
            "Epoch 25/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.1355 - accuracy: 0.9531 - val_loss: 1.7798 - val_accuracy: 0.6667\n",
            "Epoch 26/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0873 - accuracy: 0.9708 - val_loss: 1.8193 - val_accuracy: 0.6708\n",
            "Epoch 27/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0914 - accuracy: 0.9698 - val_loss: 1.9370 - val_accuracy: 0.6750\n",
            "Epoch 28/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0750 - accuracy: 0.9792 - val_loss: 1.7676 - val_accuracy: 0.6625\n",
            "Epoch 29/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0781 - accuracy: 0.9750 - val_loss: 1.9056 - val_accuracy: 0.6500\n",
            "Epoch 30/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0684 - accuracy: 0.9750 - val_loss: 1.9720 - val_accuracy: 0.6208\n",
            "Epoch 31/60\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0765 - accuracy: 0.9740 - val_loss: 1.8181 - val_accuracy: 0.6792\n",
            "Epoch 32/60\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.0730 - accuracy: 0.9708 - val_loss: 1.8271 - val_accuracy: 0.7083\n",
            "Epoch 33/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0437 - accuracy: 0.9875 - val_loss: 2.2608 - val_accuracy: 0.6875\n",
            "Epoch 34/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 2.2610 - val_accuracy: 0.6708\n",
            "Epoch 35/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0624 - accuracy: 0.9802 - val_loss: 2.2014 - val_accuracy: 0.6833\n",
            "Epoch 36/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0554 - accuracy: 0.9844 - val_loss: 1.9659 - val_accuracy: 0.6917\n",
            "Epoch 37/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0430 - accuracy: 0.9875 - val_loss: 2.0619 - val_accuracy: 0.7042\n",
            "Epoch 38/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0471 - accuracy: 0.9812 - val_loss: 2.0722 - val_accuracy: 0.6833\n",
            "Epoch 39/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0411 - accuracy: 0.9844 - val_loss: 2.1901 - val_accuracy: 0.6667\n",
            "Epoch 40/60\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0546 - accuracy: 0.9854 - val_loss: 2.2795 - val_accuracy: 0.7208\n",
            "Epoch 41/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0625 - accuracy: 0.9792 - val_loss: 2.1542 - val_accuracy: 0.7000\n",
            "Epoch 42/60\n",
            "16/16 [==============================] - 2s 94ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 2.0072 - val_accuracy: 0.6917\n",
            "Epoch 43/60\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 2.1970 - val_accuracy: 0.6833\n",
            "Epoch 44/60\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0372 - accuracy: 0.9865 - val_loss: 2.3238 - val_accuracy: 0.6875\n",
            "Epoch 45/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 2.2157 - val_accuracy: 0.6750\n",
            "Epoch 46/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0397 - accuracy: 0.9885 - val_loss: 2.3341 - val_accuracy: 0.6750\n",
            "Epoch 47/60\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 2.3277 - val_accuracy: 0.6708\n",
            "Epoch 48/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0252 - accuracy: 0.9906 - val_loss: 2.6280 - val_accuracy: 0.6375\n",
            "Epoch 49/60\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0615 - accuracy: 0.9844 - val_loss: 2.4538 - val_accuracy: 0.6458\n",
            "Epoch 50/60\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0709 - accuracy: 0.9719 - val_loss: 1.8730 - val_accuracy: 0.6708\n",
            "Epoch 51/60\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0486 - accuracy: 0.9865 - val_loss: 2.0076 - val_accuracy: 0.6708\n",
            "Epoch 52/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0440 - accuracy: 0.9844 - val_loss: 2.2278 - val_accuracy: 0.6667\n",
            "Epoch 53/60\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0525 - accuracy: 0.9823 - val_loss: 2.2824 - val_accuracy: 0.6958\n",
            "Epoch 54/60\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0411 - accuracy: 0.9906 - val_loss: 2.3518 - val_accuracy: 0.7000\n",
            "Epoch 55/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0486 - accuracy: 0.9865 - val_loss: 2.2990 - val_accuracy: 0.6750\n",
            "Epoch 56/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 2.2069 - val_accuracy: 0.6833\n",
            "Epoch 57/60\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 2.3244 - val_accuracy: 0.6708\n",
            "Epoch 58/60\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 2.3431 - val_accuracy: 0.7000\n",
            "Epoch 59/60\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 2.3130 - val_accuracy: 0.6917\n",
            "Epoch 60/60\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 2.4986 - val_accuracy: 0.6417\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.76       169\n",
            "           1       0.24      0.30      0.27        27\n",
            "           2       0.46      0.36      0.41        44\n",
            "\n",
            "    accuracy                           0.64       240\n",
            "   macro avg       0.49      0.48      0.48       240\n",
            "weighted avg       0.64      0.64      0.64       240\n",
            "\n",
            "Akurasi pada data uji: 0.6416666507720947\n"
          ]
        }
      ]
    }
  ]
}